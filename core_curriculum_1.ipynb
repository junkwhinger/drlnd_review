{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Reinforcement Learning\n",
    "\n",
    "강화학습이 유행이다. 강화학습 봇이 아타리도 깨고 슈퍼마리오도 깨고 퀘이크도 깬다. 어떻게 하면 나도 봇을 만들 수 있을까.\n",
    "\n",
    "<img src='assets/deepmind.gif' width=400px>\n",
    "\n",
    "\n",
    "수학의 정석을 펼치면 행렬이 나오듯 강화학습 책을 열면 먼저 MDP(Markov Decision Process)가 기다리고 있다.\n",
    "\n",
    "<img src='assets/AAMarkov.jpg' width=200px>\n",
    "*러시아의 수학자 안드레 안드레비치 마르코프*\n",
    "\n",
    "강화학습 공부를 여러번 시도했지만 MDP가 뭐지? -> 마르코프 프로세스가 뭐지? -> 전이확률이 뭐지? -> 다음에 알아보자..\n",
    "의 과정을 거친 어두운 과거가 있었다.\n",
    "\n",
    "이번에는 이론보다 먼저 문제부터 접근해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI GYM\n",
    "\n",
    "그동안 공부해봤던 딥러닝은 인풋-타겟 데이터를 준비하고 이를 사용해 네트워크를 학습시키기만 하면 되었다.  \n",
    "\n",
    "강화학습은 조금 다르다. 학습 시키는 것은 같지만, 인풋과 타겟을 준비해두는 개념은 아니다.  \n",
    "\n",
    "예를 들어 미로를 탈출하는 봇을 학습시킨다고 하면, 미로 환경을 먼저 준비해야 한다.   \n",
    "\n",
    "그 미로 환경안에서 우리의 봇은 실패와 성공을 거듭하며 탈출하는 방법을 익히게 된다.  \n",
    "\n",
    "즉, 강화학습을 하려면 환경과 에이전트(봇)을 준비해야 하는데 이 분야에서 가장 많이 활용되는 라이브러리는 OpenAI에서 제공하는 `gym`이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gym`은 여러 편리한 환경들을 미리 만들어두었다. 우리는 그것을 가져다 쓰기만 하면 된다.  \n",
    "\n",
    "처음 배우자마자 스타크래프트 AI나 퀘이크 AI를 만들 수는 없다.  \n",
    "\n",
    "가장 만만해보이는 녀석을 하나 골라보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CliffWalking-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/openai/gym/blob/master/gym/envs/toy_text/cliffwalking.py\">`CliffWalking`</a> 문제는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "cliff_env = np.ones(env.shape)\n",
    "cliff_env[3, :] = -1\n",
    "cliff_env[3, 0] = 0\n",
    "cliff_env[3, -1] = 0\n",
    "fig, ax = plt.subplots(figsize=env.shape[::-1])\n",
    "sns.heatmap(cliff_env, linewidths=1, ax=ax, cmap='RdBu')\n",
    "\n",
    "ax.text(0.2, 3.5, \"START\")\n",
    "ax.text(11.3, 3.5, \"END\")\n",
    "\n",
    "for i in range(10):\n",
    "    ax.text(i+1 + 0.2, 3.5, \"CLIFF\", color='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주인공 에이전트의 미션은 좌하단 스타팅에서 우하단 도착지까지 이동하는 것이다.  \n",
    "\n",
    "에이전트는 위, 아래, 왼쪽, 오른쪽으로 1칸씩 이동할 수 있으며 이동할때마다 -1점을 받는다.\n",
    "\n",
    "만약 CLIFF로 표시된 셀로 이동하게 되면 -100점을 받으며 에이전트는 낙사하여 게임을 다시 시작하지.\n",
    "\n",
    "이 게임의 목적은 에이전트가 살아있는 채로 스타팅에서 도착지로 가장 최적으로 도달하는 방법을 학습하는 것이다.\n",
    "\n",
    "`env` 변수에 할당한 환경에서 몇가지 정보를 뽑아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경의 크기\n",
    "env.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에이전트가 취할 수 있는 가짓수\n",
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스타팅 셀 (36번째 셀)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 우리한테 쉽다고 쉬운 문제는 아니다.\n",
    "\n",
    "이 문제를 우리가 푸는데 0.1초도 필요하지 않다. 그냥 눈으로 봐도 답은 정해져있다.  \n",
    "\n",
    "위로 1칸만 올라간다음, 11칸을 직진하고 다시 1칸을 내려오면 된다. \n",
    "\n",
    "<img src='assets/cliff_human_approach.png' width=400px>\n",
    "\n",
    "개/고양이 분류하는 딥러닝처럼 사람에게 쉬운 문제가 컴퓨터에게는 매우 어려울 수 있다.\n",
    "\n",
    "우리의 agent도 마찬가지다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그럼 어떻게 풀어야 할까?\n",
    "\n",
    "이 문제에서 agent은 매 순간 의사결정을 내려야한다. 상하좌우 4가지 action 중에 하나를 골라야 한다.  \n",
    "\n",
    "그리고 그 선택에 따라 다음 셀로 이동한 봇은 또다시 선택에 직면한다. 새로운 state에서.\n",
    "\n",
    "스타팅에 agent 대신 우리가 서서 주변을 둘러본다고 생각해보자. \n",
    "\n",
    "위에는 평지가 있고 왼편에는 깎아지듯 떨어지는 절벽이 있다. 그리고 절벽의 먼 너머에는 도착지가 있다.\n",
    "\n",
    "절벽으로 발을 내딫으면 도착지에 더 가까워지지만 목숨이 날아간다. 평지로 이동하면 거리는 줄어들지 않지만 그래도 목숨은 부지한다.\n",
    "\n",
    "우리 상식으로는 후자가 전자보다 더 value있는 행위이므로 (죽으면 말짱 소용없으니) 평지로 이동하는 것을 택한다.\n",
    "\n",
    "이렇듯 우리는 다음 action을 선택할 때 가장 value가 높은 쪽을 선택한다. \n",
    "\n",
    "<img src='assets/cliff_first_move.jpg' width=400px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agent를 움직여보자.\n",
    "\n",
    "agent는 어떻게 env (게임 환경)과 상호작용할까?  \n",
    "\n",
    "Cliff Walking 문제에서 가장 처음 시작하는 지점은 36번째 셀이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스타팅 state\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent가 취할 수 있는 action은 0, 1, 2, 3이며 각 숫자는 다음의 방향으로의 1칸 이동을 의미한다.\n",
    "\n",
    "- UP = 0\n",
    "- RIGHT = 1\n",
    "- DOWN = 2\n",
    "- LEFT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2action = {\n",
    "    0:'UP',\n",
    "    1:'RIGHT',\n",
    "    2:'DOWN',\n",
    "    3:'LEFT'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위로 이동해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, -100, False, {'prob': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env의 `step`함수에 action을 인자로 입력하면, env내의 agent의 위치정보가 갱신되고, 이에 해당하는 4가지 정보가 리턴된다.\n",
    "\n",
    "- observation(object): action으로 인해 발생하는 관측값으로, 여기서는 다음 시점의 state가 된다.\n",
    "- reward(float): action으로 인해 얻게 되는 reward값. 강화학습의 목적은 총 reward (value)를 최대화시키는 것이 된다.\n",
    "- done(boolean): env를 리셋해야하는지에 대한 불리언 값. 강화학습이 episodic task인 경우 done은 episode의 종료를 의미한다. (후에 설명)\n",
    "- info(dict): 디버깅을 위한 정보로 마지막 state 변화에 대한 raw 확률값을 담는다. 학습에는 사용하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent는 env안에서 state를 파악하고, action을 실행하여, action에 대한 reward와 다음 state 정보를 얻는다.\n",
    "\n",
    "강화학습에서는 state 파악과 action 실행을 같은 시점으로, reward와 다음 state 정보 획득을 같은 시점으로 묶는다.\n",
    "\n",
    "예를 들어 현재 시점을 t라고 하면,\n",
    "\n",
    "- agent는 env로부터 현재 state 정보 $S_t$를 얻는다.\n",
    "- agent는 일련의 판단을 통해 action $A_t$를 선택하고 실행한다.\n",
    "- env는 agent의 action에 따라 reward $R_{t+1}$을 전달한다.\n",
    "- agent의 action에 따라 새로운 state 정보 $S_{t+1}$이 agent에게 전달된다.\n",
    "\n",
    "\n",
    "<img src='assets/env_agent_interaction.jpg' width=400px>\n",
    "\n",
    "env가 리셋된 후 첫 스타팅에서는 리워드 정보가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### value는 어떻게 계산해야 할까?\n",
    "\n",
    "이처럼 agent는 현재 state에서 action을 수행한다음 env로부터 reward와 새로운 state 정보를 얻는다.\n",
    "\n",
    "문제를 풀기 위해 agent는 reward의 총합, 즉 value가 가장 큰 쪽으로 움직이도록 학습한다.\n",
    "\n",
    "그렇다면 value라는 것은 어떻게 계산해야 할까??\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src='assets/first_move.jpg' width=200px>\n",
    "\n",
    "스타팅에서 갈 수 있는 다음 state는 바로 위와 오른쪽이었다.   \n",
    "\n",
    "agent는 위 state의 value가 오른쪽 절벽의 value보다 더 높다고 판단한다.   \n",
    "\n",
    "절벽으로 이동할 때 agent는 -100을, 평지로 이동할때는 -1의 reward를 environment로부터 받는다.  \n",
    "\n",
    "그렇다면 스타팅 state에서 이동하는 경우 위 state는 -1, 오른쪽 state는 -100의 value를 가지고 있다고 생각할 수 있다.\n",
    "\n",
    "-1 > -100이므로 바로 다음 reward에 기반한 value 책정은 나쁘지 않은 방법이다.\n",
    "\n",
    "하지만 코앞의 reward만으로 우리는 의사결정을 내리지 않는다. \n",
    "\n",
    "연속적으로 action을 결정해야 하는 상황이라면, 또 지금의 action이 나중의 action에도 영향을 준다면,  \n",
    "\n",
    "지금 시점의 value는 앞으로 받게 될 reward들의 총합($G_t$)이라고 생각하는 것이 옳다.\n",
    "\n",
    "$G_t = R_{t+1} + R_{t+2} + R_{t+3} + ...$\n",
    "\n",
    "그런데 시점이 다른 두 reward의 크기가 같다해도, 언제 얻을 수 있느냐에 따라 그 가치가 달라질 수 있다.  \n",
    "\n",
    "당장 받는 1달러는 내일 받는 1달러보다 가치가 조금 더 높다. 따라서 미래 가치에 대한 discount rate인 $\\gamma$를 적용한다. \n",
    "\n",
    "discount rate를 적용된 value의 식은 아래와 같다.\n",
    "\n",
    "$G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + ...$\n",
    "\n",
    "$\\gamma$는 다음과 같은 특성을 지닌다.\n",
    "\n",
    "- $0<= \\gamma <= 1$ discount rate는 미래 가치를 조금 깎으므로 0과 1사이에 위치한 어떤 값이 된다.\n",
    "- $\\gamma$가 0이 되면 $G_t = R_{t+1}$가 되므로, agent는 바로 다음의 reward만을 신경쓰게 된다.\n",
    "- $\\gamma$가 1이 되면 $G_t = R_{t+1} + R_{t+2} + R_{t+3} + ...$가 되므로, agent는 먼 미래의 reward도 코앞의 reward만큼 중요하게 신경쓴다.\n",
    "- 즉, $\\gamma$가 커지면 커질수록 미래의 reward를 더 신경쓴다고 볼 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Step Dynamics\n",
    "\n",
    "정리하자면, agent는 현재 state에서 실행할 action을 결정해야 한다. \n",
    "\n",
    "어떤 action을 선택할까? 돌아오는 return $G_t$가 가장 높은 action을 선택한다.  \n",
    "\n",
    "앞에서 $G_t$는 당장의 reward 뿐 아니라 먼 미래의 값까지 할인해서 더한 값이라고 정의했다.\n",
    "\n",
    "즉, agent는 이런 복잡한 연속적인 의사결정의 문제를\n",
    "\n",
    "지금 이 state에서 할 수 있는 action 중에 value가 가장 높은 action은 뭐지?라는 작은 문제의 연속으로 만들어서 푼다.\n",
    "\n",
    "이를 one step dynamics라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finite MDPs\n",
    "\n",
    "지금까지 설명한 내용이 강화학습의 기본이다.\n",
    "\n",
    "우리의 agent는 절벽을 무사히 그리고 빠르게 건너는 문제를 푼다. 이 agent가 어떤 action을 선택하느냐에 따라 reward가 달라지고 (-1 or -100), 다음 state가 달라진다. agent는 변화하는 환경과 상호작용하면서 문제를 푸는 방식을 익힌다. 이것이 reinforcement learning, 강화학습이다.\n",
    "\n",
    "agent는 action을 선택함에 있어 value 최대화를 기준으로 삼는다. value는 단기적인 reward 뿐 아니라 먼 미래의 reward도 discount하여 고려한다. 즉, agent는 expected cumulative reward를 최대화하며 문제를 푸는 것을 목표로 학습한다.\n",
    "\n",
    "agent가 활동하는 environment는 one-step dynamics라는 특징을 가진다. t-1시점의 정보는 t시점으로, t시점의 정보는 t+1시점으로 사슬고리가 연결되듯 environment가 구성되어있다.\n",
    "\n",
    "이것이 바로 MDP의 속성이다. Cliff Walking 문제의 state와 action은 특히 그 경우의 수가 한정되어 있으므로 Finite MDP라고 할 수 있다. \n",
    "\n",
    "Finite MDPs는 다음과 같은 특징을 가진다.\n",
    "\n",
    "- $S$ = a finite set of states\n",
    "- $S^+$ = a finite set of states (episodic task)\n",
    "- $A$ = a finite set of actions\n",
    "- $R$ = a set of rewards\n",
    "- one-step dynamics\n",
    "- $\\gamma$ = the discount rate\n",
    "\n",
    "문제가 시작과 끝이 있으면 episodic task, 끝이 없이 계속 되는 문제를 continuous task라고 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy\n",
    "\n",
    "강화학습을 푼다는 것은, 연속적으로 의사결정을 내려야 하는 상황에서 최적의 의사결정을 내리는 추상적인 전략을 깨우친다는 것과 같다.\n",
    "\n",
    "서점에 가보면 엄청나게 많은 주식투자 책을 찾아볼 수 있다. 단기적인 시장 상황을 통해 매매하는 기술적 투자나 회사의 내재적인 가치를 판단해 저평가 주식을 찾아내는 가치 투자 등등 저마다 다양한 투자 정책을 제시한다.\n",
    "\n",
    "Cliff Walking로 마찬가지다. 시작점에서 출발한 agent가 종료지점까지 도착하는데는 다양한 길이 있다. 절벽을 따라 걸을 수도 있고, 절벽에서 멀리 떨어져서 걸을 수도 있다.\n",
    "\n",
    "policy(정책)은 $\\pi$라는 함수로 생각하면 된다.   \n",
    "이 함수에 state $s$를 입력하면 그 policy를 따르는 action $a$를 얻을 수 있다. \n",
    "\n",
    "이를 수식으로 표현하면, \n",
    "$\\pi : S \\rightarrow A$라 할 수 있다.\n",
    "\n",
    "$s$를 넣으면 무조건 policy에 따른 $a$가 100% 출력되는 policy를 deterministic policy라고 한다.\n",
    "\n",
    "그런데 우리 인생이 항상 의도한대로 흘러가지 않듯, 오른쪽으로 가려는 agent도 강한 바람에 위로 이동할 수도 있다.\n",
    "\n",
    "이렇게 확률적 요소가 반영된 policy를 stochastic policy라고 한다. \n",
    "\n",
    "이 함수는 state $s$에서 action $a$를 수행할 확률(0에서 1사이)을 리턴한다.\n",
    "\n",
    "즉, 수식으로 표현하면\n",
    "$\\pi : S \\times A \\rightarrow [0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy 구현\n",
    "\n",
    "Cliff Walking에서 각 state는 4가지 action을 수행할 수 있다. 어떤 state s에서의 policy를 각 스테이트가 가질 수 있는 4가지 액션값이 발생할 수 있는 확률 값을 담은 array라고 생각해보자.\n",
    "\n",
    "두가지 policy를 구현한 후 각 policy의 value를 살펴보자.\n",
    "\n",
    "- random_policy: 어떤 state에 있든 4가지 액션 중 하나를 랜덤하게 선택한다. (각 25%의 확률)\n",
    "- optimal_policy: 위로 한칸 이동한 후 끝까지 오른쪽으로 가서 한칸 아래로 가는 하드코딩된 최적 policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(env, state):\n",
    "    \"\"\"state에 관계없이 policy_s는 4가지 액션이 0.25의 확률을 갖는 array를 리턴한다.\"\"\"\n",
    "    \n",
    "    policy_s = np.ones(env.nA)  / env.nA\n",
    "    \n",
    "    return policy_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = random_policy(env, 12)\n",
    "np.random.choice(np.arange(env.nA), p=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_policy(env, state):\n",
    "    \"\"\"하드코딩된 optimal policy\"\"\"\n",
    "    \n",
    "    if state == 36:\n",
    "        return [1.0, 0.0, 0.0, 0.0]\n",
    "    elif state != 35:\n",
    "        return [0.0, 1.0, 0.0, 0.0]\n",
    "    elif state == 35:\n",
    "        return [0.0, 0.0, 1.0, 0.0]\n",
    "    else:\n",
    "        return [0.25, 0.25, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성한 policy를 실행하는 시뮬레이션 함수를 만들어본다. \n",
    "\n",
    "시뮬레이션 함수는 첫 스타팅 state 이후 입력받은 policyFunction에 의해 다음 action를 선택하고 실행한다. \n",
    "\n",
    "action을 실행하여 reward와 새로운 next_state를 얻는다.\n",
    "\n",
    "next_state가 종착지이거나, episode의 최대 길이에 도달하는 경우 게임을 종료한다.\n",
    "(이 구현에서는 절벽에 떨어져 -100을 받더라고 게임이 종료된 것으로 간주하지 않는다)\n",
    "\n",
    "그렇지 않은 경우, next_state는 현재 state가 되고 다시 policy에 따른 action을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " v: -1 | s: 36 | a: LEFT | r: -1 | next s: 36 | done: False\n",
      " v: -2 | s: 36 | a: UP | r: -1 | next s: 36 | done: False\n",
      " v: -3 | s: 24 | a: DOWN | r: -1 | next s: 24 | done: False\n",
      " v: -4 | s: 36 | a: DOWN | r: -1 | next s: 36 | done: False\n",
      " v: -5 | s: 36 | a: DOWN | r: -1 | next s: 36 | done: False\n",
      " v: -105 | s: 36 | a: RIGHT | r: -100 | next s: 36 | done: False\n",
      " v: -205 | s: 36 | a: RIGHT | r: -100 | next s: 36 | done: False\n",
      " v: -206 | s: 36 | a: DOWN | r: -1 | next s: 36 | done: False\n",
      " v: -207 | s: 36 | a: DOWN | r: -1 | next s: 36 | done: False\n",
      " v: -307 | s: 36 | a: RIGHT | r: -100 | next s: 36 | done: False\n",
      " v: -308 | s: 36 | a: DOWN | r: -1 | next s: 36 | done: False\n",
      " v: -309 | s: 36 | a: UP | r: -1 | next s: 36 | done: False\n",
      " v: -310 | s: 24 | a: LEFT | r: -1 | next s: 24 | done: False\n",
      " v: -311 | s: 24 | a: LEFT | r: -1 | next s: 24 | done: False\n",
      " v: -312 | s: 24 | a: RIGHT | r: -1 | next s: 24 | done: False\n",
      " v: -412 | s: 25 | a: DOWN | r: -100 | next s: 25 | done: False\n",
      " v: -512 | s: 36 | a: RIGHT | r: -100 | next s: 36 | done: False\n",
      " v: -513 | s: 36 | a: UP | r: -1 | next s: 36 | done: False\n",
      " v: -514 | s: 24 | a: UP | r: -1 | next s: 24 | done: False\n",
      " v: -515 | s: 12 | a: LEFT | r: -1 | next s: 12 | done: False\n",
      " v: -516 | s: 12 | a: DOWN | r: -1 | next s: 12 | done: False\n",
      " v: -517 | s: 24 | a: RIGHT | r: -1 | next s: 24 | done: False\n",
      " v: -518 | s: 25 | a: UP | r: -1 | next s: 25 | done: False\n",
      " v: -519 | s: 13 | a: UP | r: -1 | next s: 13 | done: False\n",
      " v: -520 | s: 1 | a: LEFT | r: -1 | next s: 1 | done: False\n",
      " v: -521 | s: 0 | a: DOWN | r: -1 | next s: 0 | done: False\n",
      " v: -522 | s: 12 | a: UP | r: -1 | next s: 12 | done: False\n",
      " v: -523 | s: 0 | a: UP | r: -1 | next s: 0 | done: False\n",
      " v: -524 | s: 0 | a: LEFT | r: -1 | next s: 0 | done: False\n",
      " v: -525 | s: 0 | a: DOWN | r: -1 | next s: 0 | done: False\n",
      "simulation finished with value = -525.\n"
     ]
    }
   ],
   "source": [
    "def run_simulation(env, policyFunction):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    MAX_EPISODE_LENGTH = 30\n",
    "    \n",
    "    # value를 쌓을 score를 정의한다.\n",
    "    score = 0\n",
    "    \n",
    "    # state를 리셋하고 스타팅 state를 얻는다.\n",
    "    state = env.reset()\n",
    "    \n",
    "    for i in range(MAX_EPISODE_LENGTH):\n",
    "        \n",
    "        # 주어진 state에서 policyFunction을 따르는 action의 확률값을 얻는다.\n",
    "        policy = policyFunction(env, state)\n",
    "        \n",
    "        # action의 확률값을 사용해 action을 선택한다.\n",
    "        action = np.random.choice(np.arange(env.nA), p=policy)\n",
    "    \n",
    "        # action을 실행하여 다음 state, reword, done 여부를 얻는다.\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # 현재 score에 reward를 더해 업데이트한다.\n",
    "        score += reward\n",
    "        \n",
    "        print(\"\\r v: {} | s: {} | a: {} | r: {} | next s: {} | done: {}\".format(score, state, int2action[action], reward, state, done))\n",
    "        sys.stdout.flush()\n",
    "        if done or i == MAX_EPISODE_LENGTH - 1:\n",
    "            print(\"simulation finished with value = {}.\".format(score))\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            state = next_state\n",
    "        \n",
    "run_simulation(env, random_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " v: -1 | s: 36 | a: UP | r: -1 | next s: 36 | done: False\n",
      " v: -2 | s: 24 | a: RIGHT | r: -1 | next s: 24 | done: False\n",
      " v: -3 | s: 25 | a: RIGHT | r: -1 | next s: 25 | done: False\n",
      " v: -4 | s: 26 | a: RIGHT | r: -1 | next s: 26 | done: False\n",
      " v: -5 | s: 27 | a: RIGHT | r: -1 | next s: 27 | done: False\n",
      " v: -6 | s: 28 | a: RIGHT | r: -1 | next s: 28 | done: False\n",
      " v: -7 | s: 29 | a: RIGHT | r: -1 | next s: 29 | done: False\n",
      " v: -8 | s: 30 | a: RIGHT | r: -1 | next s: 30 | done: False\n",
      " v: -9 | s: 31 | a: RIGHT | r: -1 | next s: 31 | done: False\n",
      " v: -10 | s: 32 | a: RIGHT | r: -1 | next s: 32 | done: False\n",
      " v: -11 | s: 33 | a: RIGHT | r: -1 | next s: 33 | done: False\n",
      " v: -12 | s: 34 | a: RIGHT | r: -1 | next s: 34 | done: False\n",
      " v: -13 | s: 35 | a: DOWN | r: -1 | next s: 35 | done: True\n",
      "simulation finished with value = -13.\n"
     ]
    }
   ],
   "source": [
    "run_simulation(env, optimal_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 policy는 종착지에 도착하지 못했을 뿐더러 value도 크게 낮은 값을 기록한다.  \n",
    "\n",
    "반대로 하드코딩한 optimal policy는 마지막 done이 True이고, 누적 값 역시 -13으로 agent가 얻을 수 있는 최대값을 얻었다.\n",
    "\n",
    "우리의 목표는 agent가 opimal policy를 얻도록 학습하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 무엇이 Optimal Policy일까?\n",
    "\n",
    "위에서 구한 랜덤 policy와 optimal policy는 무슨 차이가 있었을까? optimal policy는 누적 값이 랜덤 policy보다 높았다.\n",
    "\n",
    "누적 값은 각 state에서 얻을 수 있는 reward의 총합이었다. 그럼 누적값이 가장 큰 policy가 optimal policy일까?\n",
    "\n",
    "앞서 강화학습 문제를 Finite Markov Decision Process(Finite MDP)로 정의했다.\n",
    "\n",
    "MDP의 특징 중 하나는 One-Step Dynamics다. 해당 state에서의 의사결정은 다음 state와의 관계속에서 이루어진다.\n",
    "\n",
    "멀리 있는 누적값을 있는 그대로 고려하는 방식이 아니다.\n",
    "\n",
    "즉, 각 state에서 policy를 통해 얻을 수 있는 value를 고려해야 한다.  \n",
    "\n",
    "모든 state에서 다른 policy보다 얻을 수 있는 value가 큰 policy를 optimal policy라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-Value Functions\n",
    "\n",
    "두 policy ($\\pi_1$, $\\pi_2$)가 있다고 하자. 둘 중 어느 policy가 낫다고 할 수 있을까? \n",
    "\n",
    "임의의 state $s$에서 두 policy의 value를 비교해보자. 그리고 모든 state에서 한 policy가 다른 policy보다 value가 크다면, 그 policy는 더 좋다고 할 수 있다.\n",
    "\n",
    "어떤 state $s$에서 어떤 policy $\\pi$가 가지는 value을 구하는 함수를 state-value function이라고 하며 이를 $v_{\\pi}(s)$로 표현한다.\n",
    "\n",
    "이를 수식으로 표현하면,\n",
    "$v_{\\pi}(S) \\doteq E_{\\pi}[G_t | S_t = s]$\n",
    "\n",
    "즉, policy $\\pi$를 따를때 state $s$의 값은 해당 state가 가질 수 있는 value G_t의 기댓값이라 할 수 있다.\n",
    "\n",
    "기대값인 이유는, G_t가 확률변수이기 때문이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bellman Expectation Equation\n",
    "\n",
    "앞서 value를 계산하는 파트에서 $G_t$를 다음과 같이 정의하였다.\n",
    "\n",
    "$G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma R_{t+3} + ..$\n",
    "\n",
    "그런데 $G_t$는 다른 방식으로도 표현할 수 있다.\n",
    "\n",
    "Cliff Walking 문제를 다음과 같이 간단히 바꾸어본다.\n",
    "\n",
    "- state는 3개로 s0 -> s1 -> s2로 agent가 이동한다.\n",
    "- state를 이동할때 reward는 -1을 받는다.\n",
    "- discount rate $\\gamma$는 1로 설정한다.\n",
    "\n",
    "이는 아래 그림과 같다.\n",
    "\n",
    "<img src='assets/simple_pic1.jpg' width=400px>\n",
    "\n",
    "여기서 우리는 마지막 state에 도달했을때 얻는 value를 확실히 안다. 마지막 state에 도달하면 아무 reward를 받지 않고 이후에 받을 reward도 없으므로 이때의 value는 0이다.\n",
    "\n",
    "이 간단한 문제에서 s2는 s1에서부터 이동하므로, s1의 value는 역산하여 구할 수 있다.\n",
    "$v_{\\pi}(s1) = -1 + 0 = -1$\n",
    "\n",
    "<img src='assets/simple_pic2.jpg' width=400px>\n",
    "\n",
    "또 s1의 value를 앎으로써 s0의 value도 알 수 있다. \n",
    "$v_{\\pi}(s1) = -1 + -1 = -2$\n",
    "\n",
    "<img src='assets/simple_pic3.jpg' width=400px>\n",
    "\n",
    "즉 $v_{\\pi}(s)$는 바로 다음에 얻게 될 immediate reward와 다음 state의 value와 같다.\n",
    "\n",
    "$v_{\\pi}(s) = R_{t+1} + v_{\\pi}(s_{t+1})$\n",
    "\n",
    "이를 좀 더 일반화해서 적용해보자.\n",
    "일반적으로 state는 여러 액션을 가질 수 있으므로 다음 reward와 그 다음 state의 value는 확률변수가 된다. 또 다음 state의 value에는 discount가 적용되므로\n",
    "위 식에 $\\gamma$를 곱하고 확률변수의 기댓값 $E$를 씌우면 아래와 같은 식이 된다.\n",
    "\n",
    "$v_{\\pi}(s) = E[R_{t+1} + \\gamma v_{\\pi}(S_{t+1}) | S_t = s]$\n",
    "\n",
    "이것이 Bellman expectation equation이다.\n",
    "\n",
    "이로서 state가 가지는 value인 $G_t$를 reward와 다음 state의 value로 구할 수 있게 되었다. \n",
    "\n",
    "policy $\\pi$가 deterministic하다면 공식은 다음과 같이 바꿔쓸 수 있다.\n",
    "\n",
    "$v_{\\pi}(s) = \\Sigma_{s^\\prime \\in S^+, r \\in R} p(s^\\prime, r|s, \\pi(s))(r+ \\gamma v_{\\pi}(s^\\prime)$\n",
    "\n",
    "$\\pi(s)$는 state s에 대한 policy에 따른 action이 된다. 즉, $p(s^\\prime, r|s, \\pi(s))$는 state s와 action a가 주어졌을 때 새로운 state $s\\prime$과 reward r이 리턴될 확률이다. 그 다음은 그 action에 대한 immediate reward r과 다음 state $s\\prime$의 discounted된 state value를 더한 보상의 총합이 된다. \n",
    "\n",
    "이를 에피소드의 모든 state $S^+$와 모든 Reward에 대해서 다 합치면 $v_{\\pi}(s)$를 구할 수 있다.\n",
    "\n",
    "만약 $\\pi$가 action이 확률적으로 결정되는 stochastic policy라면 $\\Sigma$에 action이 하나 더 추가되고 뒷단에 $\\pi(a|s)$(state $s$가 주어졌을 때 policy $\\pi$가 action $a$를 선택할 확률)가 추가된다.\n",
    "\n",
    "$v_{\\pi}(s) = \\Sigma_{s^\\prime \\in S^+, r \\in R, a \\in A} \\pi(a|s)p(s^\\prime, r | s, a)(r + \\gamma v_{\\pi}(s^\\prime))$\n",
    "\n",
    "\n",
    "Bellman Equation은 이것 말고도 3개가 더 있는데, 모두 value function이 재귀적인 관계임을 보여준다.\n",
    "\n",
    "앞서 살펴보았던 MDP의 One-Step Dynamics (앞뒤로 위치한 state간에 가지는 관계)를 생각해보면 Bellman Equation과 맞닿아있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action-Value Functions\n",
    "\n",
    "앞서 각 state에서의 value를 구할 수 있는 state value function에 대해 알아보았다. value는 state에 따라서도 다르지만 각 state에서 취하는 action에 따라서도 달라질 수 있다. 각 state의 action별로 value를 구할 수 있는 function이 action-value function이다.\n",
    "\n",
    "action value function은 state $s$와 action $a$를 인자로 받아 policy $\\pi$를 따를때의 value를 리턴한다. 이를 $q_\\pi$로 표기한다.\n",
    "\n",
    "$q_{\\pi}(s, a) \\doteq E_{\\pi}[G_t | S_t = s, A_t = a]$\n",
    "\n",
    "모든 최적의 policy들은 같은 action-value function $q^*$를 가지며 이를 optimal action-value function이라고 한다.\n",
    "\n",
    "state-value function $v$와 마찬가지로, $\\pi^\\prime$을 따르는 모든 state와 action에서의 value가 $\\pi$보다 클때 $\\pi^\\prime$을 최적의 policy $\\pi^*$로 정의한다.\n",
    "\n",
    "action-value function은 어떻게 구현할까?\n",
    "\n",
    "Cliff Walking 문제에서 각 state에는 4가지 action 옵션이 존재한다. action-value function은 각 state를 key로, 4가지 action의 value값의 array를 value로 하는 dictionary로 구성해볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = defaultdict(lambda x: np.zeros(env.action_space.n))\n",
    "Q[36] = [10, 100, -1, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문제에서 Q는 state x action 크기의 테이블로 볼 수 있다. 처음에는 모든 값이 0으로 시작하지만, 차츰 학습을 해나가면서 Q 테이블을 업데이트할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Q[36])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing up\n",
    "\n",
    "지금까지 우리는 강화학습의 문제를 정의하고, 어떻게 풀지를 알아보았다.\n",
    "\n",
    "강화학습은 sequential한 의사결정을 해야 하는 상황에서 environment와 agent간의 상호작용을 통해 문제를 푼다.\n",
    "\n",
    "sequential한 의사결정의 문제를 우리는 Markov Decision Process로 정의하여 푼다.\n",
    "\n",
    "MDP는 One-Step dynamics라는 성질을 가진다. 현재 state와 거기서의 action이 다음 시점의 reward와 next state로 이어진다.\n",
    "\n",
    "state와 action의 가짓수가 유한한 형태를 Finite MDP라고 한다.\n",
    "\n",
    "주어진 state에서 어떤 action을 할 것인가를 결정하는 정책을 policy라고 한다.\n",
    "\n",
    "강화학습은 문제를 잘 푸는 policy를 얻는 것이다. \n",
    "\n",
    "좋은 policy란 각 state 관점에서 얻을 수 있는 value가 가장 큰 policy다.\n",
    "\n",
    "지금 action을 함으로써 얻는 reward만이 value를 설명할 수 없다.\n",
    "\n",
    "앞으로 받게 될 미래의 불확실한 reward까지도 고려해야 한다.\n",
    "\n",
    "미래의 값은 아직 실현되지 않았으므로, discount rate $\\gamma$를 곱해 더한다.\n",
    "\n",
    "optimal policy를 얻기 위해 우리는 우리의 policy가 각 state에서 어떤 value를 가지는지 평가해야 한다.\n",
    "\n",
    "이를 위해 state-value function $v_{\\pi}(s)$를 구한다.\n",
    "\n",
    "각 state에서의 value가 가장 큰 policy가 optimal policy $\\pi^*$가 된다.\n",
    "\n",
    "MDP의 One-Step Dynamics에 따라 각 state에서의 value $G_t$는 바로 다음의 reward와 다음 state에서의 discounted value로 표현할 수 있다. 이 확률 변수에 기댓값을 씌운 것이 Bellman Expectation Equation이다.\n",
    "\n",
    "$v_π(s)=E[R_{t+1}+γv_π(S_{t+1})|S_t=s]$\n",
    "\n",
    "그런데 state뿐만 아니라 그 state에서의 action에 따라 value가 달라질 수 있다.\n",
    "\n",
    "policy $\\pi$를 따를때 state와 action의 value를 리턴하는 함수를 action-value function $q_{\\pi}$라고 한다. \n",
    "\n",
    "optimal policy는 모두 같은 q함수를 가진다. \n",
    "\n",
    "q함수만 확보하면 그 다음부터는 각 state에서 value를 최대화하는 action을 선택하여 실행하기만 하면 된다. 그것이 바로 optimal policy가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Methods\n",
    "\n",
    "우리의 agent는 처한 state에서 action을 해나가면서 reward를 얻는다. (interaction)\n",
    "\n",
    "이를 통해 어떤 state에서 어떤 action을 하면 어느 정도의 value를 얻는지 학습한다. (state-value function or action-value fucntion)\n",
    "\n",
    "그리고 각 state나 state-action에서 얻을 수 있는 value가 가장 큰 선택을 한다. (choosing action that maximises return value)\n",
    "\n",
    "그러니까 우리는 정확한 state-value function이나 action-value function을 얻기만 하면 된다. 그 다음에는 argmax하면 되니까.\n",
    "\n",
    "어떤 state나 state-action 페어가 어떤 value를 가질지 예측하는 것을 prediction problem이라고 한다. 그리고 그를 통해 얻은 $v$나 $q$에서 행동을 하는 것을 control problem이라고 한다.\n",
    "\n",
    "Finite MDP 형식의 강화학습 문제를 풀 때, policy $\\pi$를 따르는 action-value function $q_{\\pi}$(Q table)를 추정한다. \n",
    "\n",
    "대체 값을 어떻게 추정할 수 있을까?\n",
    "\n",
    "위에서 우리는 $G_t$를 $R_{t+1} + \\gamma q_{\\pi}(s, a) (s \\in S, a \\in A)$와 같은 형식으로 정의했다.\n",
    "\n",
    "즉, 지금 state에서의 value은 바로 다음에 얻게 될 reward와 그 다음 시점의 value인데, 가보지 않은 미래의 value를 어떻게 알 수 있다는 말이지?\n",
    "\n",
    "또 문제를 복잡하게 만드는 것은 model이다. 위로 이동한다고 할때 강풍이 불거나 실족하는 등 낮은 확률도 오른쪽으로 이동할 수 있다. 실수할 확률을 안다면 계산할 수 있겠지만 실제 문제를 풀 때 확률을 알 수 있는 경우는 드물다.\n",
    "\n",
    "state간 전이 확률(model)을 모르는 경우 어떻게 value를 적절하게 측정할 수 있을까? 이때 사용할 수 있는 방법이 Monte Carlo Prediction이다.\n",
    "\n",
    "Monte Carlo Methods는 간단히 표현하자면 닥치고 돌려보는 것이다. 강풍이 불고 실족을 할 미지의 가능성이 조금 있더라도, 우리가 엄청나게 많이 가보고 그 평균을 내면 정답에 가깝게 다가갈 수 있다.\n",
    "\n",
    "<a href=\"https://jsideas.net/montecarlo_visualisation/\">Monte Carlo Approximation</a>\n",
    "\n",
    "Monte Carlo Methods에는 두가지 방법이 있다.\n",
    "\n",
    "Cliff Walking 문제에서 우리는 갔던 state를 재방문할 수도 있다. 또 그 state에서 행했던 action을 같은 episode내에서 반복할 수도 있다. \n",
    "\n",
    "First-visit MC는 무조건 처음 방문한 (s, a)만을 사용해서 q함수의 값을 업데이트한다.\n",
    "\n",
    "Every-visit MC는 방문한 (s, a)의 value들의 평균을 사용해서 q함수의 값을 업데이트한다.\n",
    "\n",
    "Every visit MC를 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(env):\n",
    "    return np.ones(env.action_space.n) / env.nA\n",
    "\n",
    "def generate_episode(policy, env):\n",
    "    \n",
    "    MAX_EPISODE_LENGTH = 500\n",
    "    \n",
    "    s = env.reset()\n",
    "    i = 0\n",
    "    record = []\n",
    "    \n",
    "    while True:\n",
    "        i += 1\n",
    "        a = np.random.choice(env.nA, p=policy)\n",
    "        next_s, r, done, info = env.step(a)\n",
    "        record.append([s, a, r])\n",
    "        \n",
    "        if done or i == MAX_EPISODE_LENGTH:\n",
    "            break\n",
    "        else:\n",
    "            s = next_s\n",
    "    \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = random_policy(env)\n",
    "\n",
    "# generate_episode(policy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 499 done with value(s_0): -1270.8386261637955"
     ]
    }
   ],
   "source": [
    "def mc_prediction(policy, env, gamma):\n",
    "    \n",
    "    # Q table\n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    # s, a 발생횟수\n",
    "    N = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    # return sum\n",
    "    return_sum = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    NUMBER_OF_EPISODES = 500\n",
    "    \n",
    "    for i_episode in range(NUMBER_OF_EPISODES):\n",
    "        \n",
    "        episode = generate_episode(policy, env)\n",
    "        states, actions, rewards = zip(*episode)\n",
    "        discounts = np.array([gamma ** i for i in range(len(rewards) + 1)])\n",
    "        for t, state in enumerate(states):\n",
    "            \n",
    "            action = actions[t]\n",
    "            rewards_from_t_plus_1 = rewards[t:]\n",
    "            corresponding_discounts = discounts[:-(1+t)]\n",
    "            return_sum[state][action] += sum(rewards_from_t_plus_1 * corresponding_discounts)\n",
    "            N[state][action] += 1.0\n",
    "            Q[state][action] = return_sum[state][action] / N[state][action]\n",
    "        \n",
    "        print(\"\\repisode {} done with value(s_0): {}\".format(i_episode, sum(rewards * discounts[:-1])), end=\"\")\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    policy = dict((k, np.argmax(v)) for k, v in Q.items())\n",
    "    return policy, Q\n",
    "    \n",
    "policy = random_policy(env)         \n",
    "policy, Q = mc_prediction(policy, env, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_policy(policy):\n",
    "\n",
    "    cliff_env = np.ones(env.shape)\n",
    "    cliff_env[3, :] = -1\n",
    "    cliff_env[3, 0] = 0.5\n",
    "    cliff_env[3, -1] = 0.5\n",
    "    fig, ax = plt.subplots(figsize=env.shape[::-1])\n",
    "    sns.heatmap(cliff_env, linewidths=1, ax=ax, cmap='RdBu')\n",
    "\n",
    "    for k, v in policy.items():\n",
    "        \n",
    "        rowNum = k // 12\n",
    "        colNum = k % 12\n",
    "        ax.text(colNum + 0.2, rowNum + 0.5, int2action[v], color='white')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "visualize_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스타팅 state에서 시작해보면 뭔가 절벽으로는 안가는 것 같지만 학습이 잘 되었다고 보기도 어렵다. 그러나 완전 랜덤인 policy만을 사용해서 500번 시뮬레이션한 다음 뽑은 결과로는 나쁘지 않아보인다. 어쨌든 절벽은 피하니까."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Policies vs. Epsilon-Greedy Policies\n",
    "\n",
    "위에서는 상하좌우 중 하나를 랜덤하게 고르는 policy를 MC 시뮬레이션에 넣어 돌려보고 그에 따른 Q함수(테이블)을 구할 수 있었다.\n",
    "\n",
    "그 Q함수 테이블은 state의 갯수 x action의 갯수만큼의 크기를 가지는데, 각 state별로 가장 value가 큰 action을 골라 위에서 어떤 행동을 해야 할지 결정했다.\n",
    "\n",
    "각 state에서 value가 가장 큰 action이 바로 greedy action이다. 또 value를 최대화시키는 action을 고르는 것을 greedy policy를 따른다고 한다.\n",
    "\n",
    "greedy policy는 그럴듯 해보이지만, greedy라는 수식어가 붙는 다른 표현들처럼 그렇게 긍정적이지만은 않다.\n",
    "\n",
    "새로 이사간 마을에서 근처 밥집을 찾는다고 생각해보자. 이사를 왔으므로 정보가 없어 레스토랑에 대한 value는 모두 0인 상태다. 여기서 운좋게 그럭저럭 적당한 밥집을 찾아 적당히 식사를 즐기게 된다면, 이 행동에는 +점수가 부여된다. \n",
    "\n",
    "이를 바탕으로 value 함수를 업데이트하게 되면 주어진 상태에서 최고의 value를 찾아가는 greedy policy로는 그 식당만 계속 가게 된다. 그렇게 되면 그 옆에 있는 최고의 맛집은 놓치게 되는 셈.\n",
    "\n",
    "즉, 어느정도 최적화된 액션을 찾았다하더라도 어느정도 다른 선택을 할 필요가 있다. 이것이 바로 Epsilon-Greedy Policy $\\epsilon-greedy$ policy다.\n",
    "\n",
    "e-greedy policy는 아주 작은 확률 $\\epsilon$로 랜덤한 액션을 택한다. 반대의 경우인 $1-\\epsilon$의 확률로 greedy action을 선택한다.\n",
    "\n",
    "즉 주어진 state에서 가장 value가 높은 값에 대한 action은 $1-\\epsilon + {\\epsilon \\over nA}$의 확률로 선택되고\n",
    "나머지 액션들은 $nA \\over \\epsilon$만큼의 선택확률을 갖게 된다.\n",
    "\n",
    "간단히 파이썬 함수로 구현해보면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9625, 0.0125, 0.0125, 0.0125])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prob(Q_s, env, epsilon):\n",
    "    non_greeey_prob = epsilon / env.nA\n",
    "    policy_s = np.ones(env.action_space.n) * non_greeey_prob\n",
    "    \n",
    "    greedy_idx = np.argmax(Q_s)\n",
    "    policy_s[greedy_idx] += 1 - epsilon\n",
    "    \n",
    "    return policy_s\n",
    "    \n",
    "Q_s = [10, 1, 2, -3]\n",
    "get_prob(Q_s, env, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Control\n",
    "prediction problem은 state-action이 가지는 value를 추정하는 문제였다.\n",
    "\n",
    "control problem은 env와의 interaction을 통해 optimal policy $\\pi^*$를 결정하는 문제다.\n",
    "\n",
    "Monte Carlo control method는 Q함수를 추정하는 policy evaluation과 optimal policy를 찾아나가는 policy improvement를 번갈아가면서 계속한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration vs. Exploitation\n",
    "\n",
    "모든 강화학습 agent는 Exploration-Exploitation Dilemma를 겪는다. 좋은 전략을 찾게 되면 그것을 활용해야 하지만 (exploit) 어느정도 더 나은 전략을 찾기 위한 탐색(explore)을 계속해야 한다. 그 밸런스를 찾아야 함.\n",
    "\n",
    "MC Control을 통해 optimal policy에 도달하기 위해서는 Greedy in the Limit with Infinite Exploration(GLIE)라는 조건을 만족해야 함.\n",
    "\n",
    "- 모든 state-action pair s, a는 무한히 많은 횟수로 반복되어야 하며\n",
    "- policy는 Q함수를 사용해 greedy한 action을 수행하는 policy로 수렴해야 한다.\n",
    "\n",
    "이러한 조건이 만족되면 agent는 모든 타임 스텝에서 explore를 포기하지 않게 되고, 시간이 갈수록 기존에 쌓은 지식을 더 exploit하게 된다. \n",
    "\n",
    "이 조건을 만족하기 위해서 보통 $\\epsilon-greedy$ policy의 $\\epsilon$값을 점차 수정하면 된다. 예를 들어 $\\e$값은 무조건 0보다 큰 값을 유지하되, step i에 따라서 조금씩 discount를 해나가면, i가 무한해짐에 따라 $\\epsilon_i$는 0에 근접해진다. 예를 들어 $e_i = {1 \\over i}$로 설정할 수 있겠다.\n",
    "\n",
    "실 구현할때는 얘기가 좀 다름. 수학적으로 convergence가 검증되지 않았더라도 보통 이런 방식을 통해 더 나은 결과를 얻을 수 있다.\n",
    "\n",
    "- fixed $\\epsilon$\n",
    "- 작은 양의 실수에 이를때까지만 discount하기 (ex 0.1)\n",
    "\n",
    "이렇게 하는 이유는, 너무 빨리 $\\epsilon$을 깎아버리면 나중 episode에서는 새로운 시도를 그만큼 덜하게 된다.\n",
    "DQN 논문에서는 첫 1백만 프레임에서는 1.0부터 0.1까지 리니어하게 깎고, 그 이후로는 0.1을 픽스해서 적용했다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Mean\n",
    "\n",
    "MC는 수많은 에피소드 샘플을 생성한다음, 그 값을 평균내어 state action 페어의 value를 추정한다.\n",
    "\n",
    "예를 들어 학습을 위해 총 4개의 epsiode를 생성했다고 가정하자. 그리고 그 episode를 하나씩 돌면서 어떤 임의의 state action 페어의 return값을 사용해 Q value를 업데이트한다고 생각해보자.\n",
    "\n",
    "episode의 순번을 N, 각 순번의 에피소드에서 s, a 페어에 해당하는 return이 G, 그리고 G를 누적하여 업데이트한 값이 Q라고 했을때\n",
    "\n",
    "아래 그림에서 Q의 값은 어떻게 될까?\n",
    "\n",
    "<img src='assets/incremental_mean.jpg' width=400px>\n",
    "\n",
    "MC는 에피소드가 갱신될때마다, 해당 state action 페어가 가진 G값들의 평균을 내어 Q를 업데이트한다. 즉, 첫번째 episode의 G가 2인 상황에서 G값으로 8이 들어온다면, (2+8) /2로 Q의 값을 5로 업데이트한다.\n",
    "\n",
    "과거의 G값을 계속 어딘가에 저장해두려면 귀찮고 번거롭다. 과거 G값없이도 현재의 에피소드 넘버와 직전 Q값, 그리고 현재 G값을 알면 $Q \\leftarrow Q + {1\\over N}(G-Q)$을 사용해 업데이트할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Alpha\n",
    "\n",
    "그런데 $Q \\leftarrow Q + {1 \\over N}(G-Q)$는 한가지 문제가 있다.\n",
    "\n",
    "G는 현재 에피소드의 return 값이다. 즉 최근의 관측값이다. \n",
    "Q는 직전까지의 G의 평균값으로, 우리가 믿고 가는 값이다.\n",
    "G-Q는 그 둘 사이의 괴리로, 오차라고 생각할 수 있다.\n",
    "\n",
    "위 식은 그 오차에다가 $1 \\over N$만큼을 곱한 것을 Q에다 더해서 업데이트한다.\n",
    "딥러닝에서 학습할때 쓰이는 learning rate $\\eta$와 비슷한 느낌이다.\n",
    "\n",
    "그런데 이 업데이트 폭이 $1 \\over N$이라는 것은 초반 에피소드에서는 그 값이 크지만 나중에 가서는 엄청나게 작아짐을 의미한다.\n",
    "\n",
    "후반부 에피소드에서 중요한 정보를 얻는다고 해도 그 정보의 가치가 전반부에 비해 훨씬 작아진다.\n",
    "\n",
    "이러한 문제를 해결하기 위해서 $1 \\over N$을 작은 상수 $\\alpha$로 두는 방식이 제안되었다. 이를 Constant-alpha 방식이라고 한다.\n",
    "$\\alpha$를 크게 가져가면 업데이트 보폭이 커지므로 학습은 빨라지지만, 너무 큰 $\\alpha$값은 optimal policy $\\pi^*$로의 convergence를 저해할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000/10000."
     ]
    }
   ],
   "source": [
    "def get_probs(Q_s, epsilon, nA):\n",
    "    non_greeey_prob = epsilon / nA\n",
    "    policy_s = np.ones(nA) * non_greeey_prob\n",
    "    \n",
    "    greedy_idx = np.argmax(Q_s)\n",
    "    policy_s[greedy_idx] += 1 - epsilon\n",
    "    \n",
    "    return policy_s\n",
    " \n",
    "def generate_episode_from_Q(env, Q, epsilon, nA, max_episode_len):\n",
    "    episode = []\n",
    "    state = env.reset()\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        cnt += 1\n",
    "        action = np.random.choice(np.arange(nA), p=get_probs(Q[state], epsilon, nA)) \\\n",
    "            if state in Q else env.action_space.sample()\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        episode.append((state, action, reward))\n",
    "        state = next_state\n",
    "        if done or cnt == max_episode_len:\n",
    "            break\n",
    "    return episode\n",
    "\n",
    "\n",
    "def update_Q(env, episode, Q, alpha, gamma):\n",
    "    # Q <- Q + alpha(G-Q)\n",
    "\n",
    "    states, actions, rewards = zip(*episode)\n",
    "    discounts = np.array([gamma ** i for i in range(len(rewards) + 1)])\n",
    "    for i, state in enumerate(states):\n",
    "        action = actions[i]\n",
    "        rewards_from_this_point = rewards[i:]\n",
    "        corresponding_discount_rates = discounts[:-(1+i)]\n",
    "        G = sum(rewards_from_this_point * corresponding_discount_rates)\n",
    "        old_Q = Q[state][action]\n",
    "        Q[state][action] = old_Q + alpha * (G - old_Q)\n",
    "    return Q\n",
    "    \n",
    "\n",
    "def mc_control(env, num_episodes, alpha, gamma, eps_start=1.0, eps_min = 0.1, eps_decay_duration=3000):\n",
    "    \n",
    "    nA = env.action_space.n\n",
    "    \n",
    "    # Q table\n",
    "    Q = defaultdict(lambda: np.zeros(nA))\n",
    "    \n",
    "    epsilon_decay_angle = (eps_min - eps_start) / eps_decay_duration\n",
    "    epsilon = eps_start\n",
    "    \n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "        \n",
    "        if i_episode % 1000 == 0:\n",
    "            print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        epsilon += epsilon_decay_angle\n",
    "        epsilon = max(eps_min, epsilon)\n",
    "        episode = generate_episode_from_Q(env, Q, epsilon, nA, max_episode_len=500)\n",
    "        Q = update_Q(env, episode, Q, alpha, gamma)\n",
    "        policy = dict((k, np.argmax(v)) for k, v in Q.items())\n",
    "    return policy, Q\n",
    "\n",
    "policy, Q = mc_control(env, 10000, 0.02, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와... 신기하다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal-Difference Methods\n",
    "\n",
    "MC를 사용해 꽤 좋은 성과를 낼 수 있었다. 비록 절벽에 딱 붙어서 움직이는 효율적인 모습까지는 아니었지만 그래도 괜찮은 성능을 보였다.\n",
    "\n",
    "MC 방식의 단점은 Episode가 끝난 후 업데이트가 이루어진다는 것이다. 위 구현에서 `max_episode_len` 파라미터를 500 정도로 설정해두었다. 왜 그랬을까?\n",
    "\n",
    "`generate_episode_from_Q`에서는 action의 결과로서 game이 끝날때까지 (done이 True)일때까지 계속 action을 실행한다. Cliff Walking 문제에서 처음에 완전 랜덤한 액션을 하는 agent가 랜덤한 액션만으로 종착지까지 도달하도록 기대하는 것은 너무 어려운 문제다. 실제로 `max_episode_len`를 더 크게 설정하거나 아예 없애버리면 episode가 기약없이 계속 생성된다.\n",
    "\n",
    "또 다른 문제는 continuous task에 대한 알고리즘의 적용이다. 시작과 끝이 정해져있지 않은 오픈 월드의 게임에서는 애초에 episode의 끝이 없기에 MC를 그대로 적용할 수 없다. MC에서는 episode가 끝나야 비로소 Q함수를 업데이트할 수 있기 때문이다.\n",
    "\n",
    "Temporal-Difference Methods는 이러한 MC의 단점을 보완한다. 에피소드가 다 생성된 후에 Q함수를 업데이트하는 것이 아니라, TD는 매 타임스텝마다 value function을 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD Control\n",
    "\n",
    "TD 방법에는 우리가 많이 들어본 것들이 나온다.\n",
    "\n",
    "### Sarsa(0) a.k.a Sarsa\n",
    "Sarsa는 on-policy TD control method다.\n",
    "Sarsa는 state, action, reward, state, action의 연속 시퀀스에서 따온 이름이다.\n",
    "\n",
    "MC와 달리 TD는 매 타입스텝마다 Q함수를 업데이트한다고 했다.\n",
    "즉, $G_t$를 구하는 것이 아닌, action의 결과로서 얻는 reward와 그 다음 state, action을 사용해서 $G_t$를 근사한다.\n",
    "\n",
    "$Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha(R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t))$\n",
    "\n",
    "즉 매 타임스텝에서 s에 a를 써서 r, next_s를 얻는다.\n",
    "그리고 현재 사용하는 $\\epsilon-greedy$를 사용해 next_a를 뽑아놓는다.\n",
    "\n",
    "그러면 현재 시점(t)에서 보자면, 무한히 먼 미래까지 확장된 $G_t$까지는 아니지만 그래도 다음 액션으로 인한 value까지는 감안한 value로 Q함수를 업데이트하게 되는 것이다.\n",
    "\n",
    "Sarsa를 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def update_Q(Qsa, Qsa_next, reward, alpha, gamma):\n",
    "    # Q[s, a] = Q[s, a] + a * (r_1 + gamma * Qsa_next - Qsa)\n",
    "    Qsa = Qsa + alpha * (reward + gamma * Qsa_next - Qsa)\n",
    "    return Qsa\n",
    "\n",
    "def sarsa(env, num_episodes, alpha, gamma, eps_start=1.0, eps_min = 0.1, eps_decay_duration=3000):\n",
    "    \n",
    "    MAX_EPISODE_LENGTH = 300\n",
    "    PLOT_EVERY = 100\n",
    "    \n",
    "    tmp_scores = deque(maxlen=PLOT_EVERY)\n",
    "    scores = deque(maxlen=num_episodes)\n",
    "    \n",
    "    #init Q\n",
    "    Q = defaultdict(lambda: np.zeros(env.nA))\n",
    "    \n",
    "    epsilon_decay_angle = (eps_min - eps_start) / eps_decay_duration\n",
    "    epsilon = eps_start\n",
    "    \n",
    "    \n",
    "    # loop over ep\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        \n",
    "        if i_episode % 100 == 0:\n",
    "            print(\"\\rEpisode {}/{}\".format(i_episode, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()   \n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        epsilon += epsilon_decay_angle\n",
    "        epsilon = max(eps_min, epsilon)\n",
    "        \n",
    "        # init state\n",
    "        state = env.reset()\n",
    "        \n",
    "        policy = get_probs(Q[state], epsilon, env.nA)\n",
    "        action = np.random.choice(np.arange(env.nA), p=policy)\n",
    "        \n",
    "        for i in range(MAX_EPISODE_LENGTH):\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                \n",
    "                Q[state][action] = update_Q(Q[state][action], 0, reward, alpha, gamma)\n",
    "                tmp_scores.append(score)\n",
    "                break\n",
    "            else:\n",
    "                \n",
    "                # next action\n",
    "                policy = get_probs(Q[state], epsilon, env.nA)\n",
    "                next_action = np.random.choice(np.arange(env.nA), p=policy)\n",
    "                \n",
    "                # update Q\n",
    "                Q[state][action] = update_Q(Q[state][action], Q[next_state][next_action], reward, alpha, gamma)\n",
    "                \n",
    "                state = next_state\n",
    "                action = next_action\n",
    "                \n",
    "        if i_episode % PLOT_EVERY == 0:\n",
    "            scores.append(np.mean(tmp_scores))\n",
    "            \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(np.linspace(0,num_episodes,len(scores),endpoint=False), np.array(scores))\n",
    "    ax.set_xlabel('Episode Number')\n",
    "    ax.set_ylabel('Average Reward (Over Next {:d} Episodes)'.format(PLOT_EVERY))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Best Average Reward over {:d} Episodes: {}\".format(PLOT_EVERY, np.max(scores)))\n",
    "    \n",
    "    policy = dict((k, np.argmax(v)) for k, v in Q.items())\n",
    "    return policy, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000/10000"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Average Reward over 100 Episodes: -22.21\n"
     ]
    }
   ],
   "source": [
    "policy, Q = sarsa(env, 10000, alpha=0.02, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarsamax\n",
    "\n",
    "Sarsa는 학습은 잘 되었지만, 쫄보처럼 멀리 돌아서간다. 이번에는 Sarsamax로 해보자.\n",
    "Sarsamax는 Q-learning이라고도 한다.\n",
    "\n",
    "Sarsa는 s에서 a를 실행한 다음 얻는 next s에 현재 policy를 적용해 next a까지 뽑았다. 그리고 Qsa를 Qsa_next를 사용해서 업데이트했다.\n",
    "\n",
    "Sarsamax는 s에서 a를 뽑은 다음 next s에서 next a를 또 뽑지 않는다. next s가 가질 수 있는 가장 높은 값을 사용해서 Qsa를 업데이트한다. 그러니까 next a를 뽑는 절차를 거치지 않는다.\n",
    "\n",
    "$\\epsilon-greedy$를 사용해서 a를 뽑았는데, 실제 Q함수를 업데이트할때 next state의 최댓값을 사용하므로 greed policy를 따른다고 볼 수 있다. 즉 실제 episode를 생성하는 policy와 학습에 사용하는 policy가 다르다. 이를 off-policy 방식이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def update_Q(Qsa, Qs_max, reward, alpha, gamma):\n",
    "    # Q[s, a] = Q[s, a] + a * (r_1 + gamma * Qs_max - Qsa)\n",
    "    Qsa = Qsa + alpha * (reward + gamma * Qs_max - Qsa)\n",
    "    return Qsa\n",
    "\n",
    "def sarsamax(env, num_episodes, alpha, gamma, eps_start=1.0, eps_min = 0.1, eps_decay_duration=3000):\n",
    "    \n",
    "    MAX_EPISODE_LENGTH = 300\n",
    "    PLOT_EVERY = 100\n",
    "    \n",
    "    tmp_scores = deque(maxlen=PLOT_EVERY)\n",
    "    scores = deque(maxlen=num_episodes)\n",
    "    \n",
    "    #init Q\n",
    "    Q = defaultdict(lambda: np.zeros(env.nA))\n",
    "    \n",
    "    epsilon_decay_angle = (eps_min - eps_start) / eps_decay_duration\n",
    "    epsilon = eps_start\n",
    "    \n",
    "    \n",
    "    # loop over ep\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        \n",
    "        if i_episode % 100 == 0:\n",
    "            print(\"\\rEpisode {}/{}\".format(i_episode, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()   \n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        epsilon += epsilon_decay_angle\n",
    "        epsilon = max(eps_min, epsilon)\n",
    "        \n",
    "        # init state\n",
    "        state = env.reset()\n",
    "        \n",
    "        policy = get_probs(Q[state], epsilon, env.nA)\n",
    "        \n",
    "        for i in range(MAX_EPISODE_LENGTH):\n",
    "            \n",
    "            #sarsamx에서는 action이 for loop 안으로 들어온다.\n",
    "            action = np.random.choice(np.arange(env.nA), p=policy)\n",
    "        \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                \n",
    "                Q[state][action] = update_Q(Q[state][action], 0, reward, alpha, gamma)\n",
    "                tmp_scores.append(score)\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # update Q\n",
    "                Q[state][action] = update_Q(Q[state][action], Q[next_state].max(), reward, alpha, gamma)\n",
    "                \n",
    "                state = next_state\n",
    "                \n",
    "        if i_episode % PLOT_EVERY == 0:\n",
    "            scores.append(np.mean(tmp_scores))\n",
    "            \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(np.linspace(0,num_episodes,len(scores),endpoint=False), np.array(scores))\n",
    "    ax.set_xlabel('Episode Number')\n",
    "    ax.set_ylabel('Average Reward (Over Next {:d} Episodes)'.format(PLOT_EVERY))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Best Average Reward over {:d} Episodes: {}\".format(PLOT_EVERY, np.max(scores)))\n",
    "    \n",
    "    policy = dict((k, np.argmax(v)) for k, v in Q.items())\n",
    "    return policy, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 100/10000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junkwhinger/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/junkwhinger/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000/10000"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEICAYAAABxiqLiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xuc1HW9x/HXLiwLyE3kpoCiCB9MDc0LZkqmoOhJKzteslTMk0ezUrtbdrHTMTPNtLyUglpmah7tHEnFyruE4gXvfLiZchEBBXYBd9ndmfPH97cwLjuzP4f57czOvJ+PB4+d+e539/f55fb7zPdelU6nERER+aCqix2AiIh0TUogIiKSFyUQERHJixKIiIjkRQlERETyogQiIiJ5UQIREZG8KIGIiEhelEBERCQv3YsdQJImTJiQHj58eLHDEBHpUl555ZXV7j64o3plnUCGDx/O3XffXewwRES6FDN7I049dWGJiEhelEBERCQvSiAiIpIXJRAREcmLEoiIiORFCURERPKiBCIiInkp63Ugsu2aW1K8uGwdc15/lw2NzcUOR0RiqK6u4sT9R7LTgF6JXkcJRN6nuSXFy8vreGrxO8xe/A5z/rWG9VHiqKoqcnAiEku3qirGDeurBCLJSaXSvPpWHU+9/i6+oo75b69n/tv1bNzUAsBug7fjU/vsxMGjBzFht4EM6lNb5IhFpJQogVSYdDrNI/NXcdezS5m1cDVrNjYBMKhPD8YO7cuJ+49k/1Hbc+CuAxnSt2eRoxWRUqYEUsaaWlIsW/Pe5vdzl6zl+kcXMW9FPYP61HL4uKEcOmYQB4/egSH9lCxE5IOJlUDMrC8wEFjl7huTDUkK5dt3vcg9zy97X9nuQ/pw+QnjOW78TvTorkl4IpK/nAnEzE4DvgzsAKwEBpjZGuBad7+tE+KTPK2qb2TGi8s5eq9hHLnnUAAG9+nJwaN3oLpao+Eisu2yJhAzuxl4Epji7mszyvsDp5jZH9z91ORDlHz8+dklNLWk+caRxu5D+hQ7HBEpQ7laIGe7e0PbQndfB1xnZjdt68XNrApYCiyIiv7p7hea2bHAD4FmYLq732BmvYBbgSFAPXC6u6/a1hjKUSqV5k9Pv8mEXQcqeYhIYrImkNbkYWbDgf6Eh/l3gF+7+9z2kkseRgPPufuxrQVmVgNcCRwAbACeNLP/Az4PvOTuPzazk4GLgPMKEEPZeXzhapa8+x7fOmpcsUMRkTIWZxT1NmAocAnwN8LDvVD2A4ab2cNmdp+ZGbAHsNDd17j7JuAJYCJwCPBA9HP3A5MKGEdZ+ePsN9hhux4cFY19iIgkIU4CSQGPAQPc/fbo/QdmZmea2cuZ/4AVwM/c/ROEBHUr0A9Yl/Gj9YQWUGZ5a5m0sWJdA/+Yt5J/338Etd27FTscESljcabx1gCXAY+Z2SeAHvlcyN2nAdMyy8ysN6FrDHd/wsx2IiSHvhnV+gJrgbqM8tYyaeP2OW/SkkpzyoE7FzsUESlzcVogZwCLgEuBwcDpBbz+j4DzAcxsPLAEeBUYY2YDzawHofvqn4QZYcdEP3c08HgB4ygLz77xLtc9sogjxg1hlx22K3Y4IlLm4iSQxcAmwqD1SkJLoFAuBT5uZo8CvwSmunsT8HVgJiFxTHf3ZcB1wJ5m9gRwFnBxAePo8hatWs+ZtzzDTgN68YsTxhc7HBGpAHG6sH4LLAcmA3OA37OlJbBN3H0N8G/tlN8L3NumbCNwQiGuW25W1Tcy9aan6VZVxc1nHMDA7fLqZRQR+UDitEBGu/sPgfeiB7sGr0vIhsZmzrxlDqvqG5k29QB1XYlIp4mTQLqb2SDYvCdWXrOwpPCaWlKce9tzvLxsHb/53EfYZ+SAYockIhUkThfWRYQB7B2B2USD3lJc6XSa79/zEo/4Ki75zN5M+pDWfIhI5+owgbj7o4CZ2WBgtbunkw9LOvKrvy/gzmeW8rUjxnDKBE3ZFZHOl2szxYeBrZKFmeHuhycaleT02lt1XP3QAj77kRFcMGlMscMRkQqVczPF6OuPgL8QurEOBD6ZdFCS2y9mOn1ru/PDT36IKh1ULiJFkmszRQcws6HufmdUfI+ZfbVTIpN2Pf36uzw0byXfnmL0711T7HBEpILFPZHwTOBp4GDCokIpgnQ6zaX3v8bQfrWccfCuxQ5HRCpcnGm8nwf2AX4BWPReiuDvr63kuTfXct4RY+nVQxslikhxdZhA3H0FYRv1h4BH3f2dxKOSrbSk0vxi5jx2HbQdJ+w/otjhiIh0nEDM7GeEDRU3Aaeb2RWJRyVbuevZJcx/ez3fPNKo6Ran4Sgikqw4YyAT3f1jAGZ2FWExoXSiDY3NXPHgfPbdeQDH7D2s2OGIiADxxkBqzKy1XhXtrA2RZN3w+GJW1jdy0b/toWm7IlIy4rRA7iCcSz4bmADcnmxIkmllXQO/fXQxx+w9jP12GVjscERENouzlckVZjYTGAfc6O6vJB+WtPrl3+bTnErx7aPGFTsUEZH3iTOI/mHCEbJLgavN7IjEoxIA5q2o485nlnDqQaMYNUjbtItIaYkzBnI90Ah8P/r3o0Qjks3++6+v0ae2O189fPdihyIispU4CaQBeAXo4e6zgZZkQxKAR3wljy9YzdeOGMP2OmFQREpQnASSJhxje5+ZnQg0JRuSNLekuOS+19hlh96c9tFRxQ5HRKRdcRLIScAt7n4VsAo4OdmQ5I5nwqLB704ZR4/uWjQoIqUp69PJzFq3bT8eGGFmZwFjgH/vjMAq1frGZq7823wOGLU9U/bSokERKV25pvHuEH3dsTMCkWDGC8tZvX4Tvz11Py0aFJGSlrUF4u63RC9/ArxIGEx/1t0v7ozAKtUDr6xg54G9+cjO2xc7FBGRnOJ0sN9AGAdpAE4zs18mG1LlWvdeE08uXM2UvYap9SEiJS/OViZ7u/uE6PVV0ZYmkoCH562kqSXNUXtq7ENESl+cFshCM9sVwMyGAG8mG1LleuDlFQztV8u+IwcUOxQRkQ7FaYEcBMwzszeAEUCjmb0FpN19p0SjqyDvbWrhkfkrOXH/kVRXq/tKREpfnM0UR3dGIJXu0fmraGhKMUXdVyLSReRaB3JhxusjMl5fl3RQleiBl99i+941HLirtmwXka4h1xjI5IzX3894rX3FC2xTc4p/vLaSyR8aSncdVysiXUSuLqyqLK8LdiKhmXUDfgnsD9QCP3b3GWZ2EHAV0Aw86O4XR6ciXguMJ+wO/B/uvrBQsRRLfUMTv3l4IfWNzVp5LiJdSq4Eks7yupBOBWrc/WNmNhw4ISq/HvgssBj4q5ntC+wK9HT3j0YJ5grgUwnFlbiGphamPfE6Nzy+mLUbmzh6r2EcsvvgYoclIhJbrgQyPNr/qqrN60LOvDoKeNnM/hr97q+aWT+g1t0XAUSnIU4ibKnyAIC7zzaz/QsYR6f79UMLuObhRRwxbgjnTRrDh0do6q6IdC25EshtbNkHK/P1n/K5kJmdCVzQpngVYYX7J4GJwE3AKUBdRp16YDegH7Auo7zFzLq7e3M+8RRTOp3mf+cu5zAbzLSpBxQ7HBGRvGRNIIXe88rdpwHTMsvM7HZghrungUfNbCwhefTNqNYXWAv0blNe3RWTB8ALS9exdM17nD9pbLFDERHJW7Gn/DwBHANgZuOBN929DthkZqPNrIrQzfU48GRG3YOAl4oT8rab8cJyenSrZvKHhhY7FBGRvMVZiZ6kG4Drov21qoCzo/KzgT8C3QizsJ4ysznAZDObFdU9oxgBb6tUKs19L73FxLGD6N+rptjhiIjkLWcCiVoFk4D+hG6kx919TqEu7u6NwBfbKZ9N2EIlsyzFlgTTZT2/ZA3L1zXwrSlW7FBERLZJrpXoPwQuIZyB/jphTcaPzey/Oim2sjTjxbfo0b2aSXuo+0pEurZcLZDJ7n5oZoGZ/RqYDfwg0ajKVGv31WFjB9O3p7qvRKRryzWIXmNmo9qUjQJSiUVT5p55Yw1v1zXyyfHaxFhEur5cLZDzgXvMrAdham0/whYi53RGYOXogZdXUNu9miPGDSl2KCIi2yzXOpDZwL5m1pew/qLO3dd3WmRl6Nk317DPyAFsV1vsyW8iItsu1yD6bmb2F+BVYBbwqpn9NVrsJx9QY3MLry2vY5+dtWWJiJSHXB+FbwQudPenWguiBXw3AR9LOrByM++teja1pNhHe16JSJnINYjeMzN5wOZuLcnDC0vXAjBe552LSJnI1QJ5wcymE3bAXUcYBzkGeLEzAis3c5esZXDfWnbs37PYoYiIFESuBPJl4NPAIYQZWHXADOCeToir7MxdspbxIwZQVVXVcWURkS4g1yysNCFZKGFso3XvNbF41QaO33d4sUMRESmYrAkk12wrd5+fTDjl6aWl4RiTfUZuX+RIREQKJ1cX1nTCQU7z2PpM9MOTDKrctA6g7z2if5EjEREpnFwJ5EjgUeBUd1/WSfGUpblL1rLb4O20fbuIlJWs03jdfSNh+/SdOy+c8pNOp5m7ZK3Wf4hI2cm5p4a7P9tZgZSrFXUNrKpv1PoPESk7xT7StuzNfVMLCEWkPCmBJGzu0rX06FbNHjv2LXYoIiIF1WECMbNPtnl/YnLhlJ9XltUxbse+1HbvVuxQREQKKtc6kE8SNk38nJkdHBV3A44D7uyE2MrC/LfrmTh2cLHDEBEpuJx7YQE7AO8BHpWlgD8lHVS5WLexiZX1jYwZ0qfYoYiIFFyurUyWALeY2Yvu/nxredQymdsZwXV1C1fVAzBmqBKIiJSfOEfj3Whm1wG/B64AxhE2VZQOLHg7HOA4ZogG0EWk/MSZhXUIMAV4E3jL3ScnG1L5WLByPT1rqhk+oFexQxERKbg4CeQLgAFXAieamU4jjGnByvXsPqQP1dXawl1Eyk+cBDIZOMTdfw4cD/wi2ZDKx8K369V9JSJlq8ME4u4nAkPM7BhgE3BY0kGVg/qGJpava9AAuoiUrQ4H0c3sK8BngIHALcDuwFcSjqvLW7hSA+giUt7idGGdTOjGWuvuvwImJBtSeViwOYGoBSIi5SlOAqkmHCKVjt43JhdO+Vi4cj09ulczcmDvYociIpKIOOtAbgMeA3Yxs/uAvxTq4mb2XcIUYYABwDB3H2ZmxwI/BJqB6e5+g5n1Am4FhgD1wOnuvqpQsRTagrfrGT24D900A0tEylScQfTfAGcB3wC+6+6XF+ri7n6pux/m7ocBS4HTzKyGMGX4SODjwFlmNhQ4B3jJ3Q8lLGq8qFBxJGHByvXqvhKRspZrM8XT2inex8z2cfffFzIIMzseWOPuD5rZh4GF7r4m+t4TwETCgsbLoh+5H/hBIWMopI2bmlm65j1O2n9ksUMREUlMri6sPdq8rwLOADYSWgAfiJmdCVzQpvgMd58DXAh8LirrB6zLqFMP9G9T3lpWkhat3ABoDywRKW+5NlO8sPW1mY0mTOGdAZyfz4XcfRowrW25mX2IMMNrYVRUB2TOfe0LrG1T3lpWkhasbN1EUVN4RaR8xVkHci4haVzg7klsojiJ0CXV6jVgjJkNBNYTuq8uB3YBjgGeBo4GHk8gloKY//Z6arpVsYtmYIlIGcs1BjIcuAl4FziwdUwiAQb8rfWNuzeZ2deBmYRB/unuvizaEfiWaExkE3BKQvFss4Ur69ltUB+6d9OJwSJSvnK1QF4hrPl4CLjGzDZ/w90L9vB293PbKbsXuLdN2UbghEJdN0kLV65nz51KdohGRKQgciWQT3VaFGVkU3OKJWve49jxOxU7FBGRROUaRH+0MwMpF2++u4GWVJrdBm9X7FBERBKlTvoCW7QqTOHdbZCm8IpIeeswgVjm4Id0aHFrAlELRETKXJwWyFZrNyS7xavWM7hvLX171hQ7FBGRRMXZTHGDmV0JOJACcPffJRpVF7Z49QZ2G6TWh4iUvzgtkFmEVd9DgR2jf5LF4lXr2W2wxj9EpPzF2Y33YuBJ4C3gHuDnSQfVVa3ZsIk1G5sYrfEPEakAcbYyuQQYQdhcsZH3b3woGRavDqcQagBdRCpBnC6sQ9z9NGC9u98C7JpwTF3WYk3hFZEKEieBdDeznkDazLoBLQnH1GU0t6RIp9Ob3y9evYGablWM2L5XEaMSEekccRLIlcCzwF7AU8A1iUbUBazduImf3fcae/5oJjc9+a/N5YtXrWfngb21iaKIVIQ403gfBv4O7A687u6rkw2pdLWk0vzuscVc+8hC1jc2M6BXDTfP+hdTDx5FdXUVi1dt0AwsEakYcT4qzwR+Cwyo9OTxrbte4OcPzOPAUQO5/7xD+dGxe/LmuxuZ/fo7tKTSvPHORg2gi0jFiDONdz/CWeSfNrM5Zvb95MMqLc0tKb5x51zufm4ZF0way7SpBzBuWD+m7DWMfj27c8ecJSxds5FNLSlGawBdRCpE3M76V4B/Eg6XOjS5cEpPKpXm63e+wF/mLudbRxnnTRqz+Xs9a7rx6X2Hc//LK3j+zXDCrlogIlIp4mymOJ0wiD4W+E93n5J4VCXkxWXr+L8XlvO1w3fn3E/svtX3TzpgJJuaU1z9jwUAGgMRkYoRZxD9buBMd093WLMM1Tc0AXDo2MHtfn/Pnfqz1/B+vLysjgG9axi4XY/ODE9EpGhytkDM7LPAN4FFZvaImXWJI2ULqaEpBUDP7t2y1jnpgJ0BtImiiFSUrAnEzE4FzgDOBsYBXwHOMLOpnRNaaWhoCusme9Zkz7XHjd+JnjXVjB3at7PCEhEpulxdWF8CJrt7Y/T+ZTM7kTCt9+akAysVjc1RC6Qmewukf68a/vyfBzO0X21nhSUiUnS5urCaM5IHAO6+ngrbyqS1BVLbPfd8g71H9GdIv56dEZKISEnI9VTsZmbvm1JkZn2B7B/Fy9DmBJKjBSIiUolydWH9BrjHzL4DLAJGAb+IyivGli4s7W8lIpIpawJx9z+bWR1wMbAbsBS42t1ndFZwpaCxqYWqKuihDRJFRN4nawIxs97uPpMwaJ7t+xsTi6xENDSnqO1eTVVVVbFDEREpKbm6sK4xs2eA2939ndZCMxsEfAHYFzg94fiKrqGpJecMLBGRSpWrC+uMaNruX8xsJLAa6Ec4G/1ad/9VJ8VYVA1NLTkXEYqIVKqcW5m4+53AndGJhNsD77j7pk6JrEQ0NKU0gC4i0o44e2Hh7g2ElkfFaWxuoVYtEBGRreijdQfUAhERaV+sFkhSzKw/cDvQB2gEvuDuK8zsIOAqoBl40N0vNrNq4FpgfFT3P9x9YdIxNjS1aBGhiEg7ck3jfRhodwt3dz+8QNefCrzk7t82sy8B3wK+AVwPfBZYDPzVzPYFdgV6uvtHowRzBfCpAsWRVUNziv69apK+jIhIl5Orb+Zs4BxgBeGBfirwa+D1Al7/JaB1C9t+QJOZ9QNq3X1RdAbJTGAScAjwAIC7zwb2L2AcWTU2tdCzg32wREQqUa5pvA5gZkOj2VgQtjb5aj4XMrMzgQvaFJ8LHGlmrwIDCcfl9gPqMurUE1bC9wPWZZS3mFl3d2/OJ564GptT6sISEWlHrDGQ6OH/NHAwkNc0XnefBkxr83vvBi5z99+a2YeB/yG0NDIP1ugLrAV6tymvTjp5QOs6ELVARETaivNk/DywD3A5YNH7QlnDllbFSqCfu9cBm8xstJlVAUcBjwNPAscARGMgLxUwjqy0El1EpH1xWiC/dPdTErr+D4AbzezLQA3hECsI4y9/JGwd/6C7P2Vmc4DJZjYLqCKclpg4TeMVEWlfnARSG3UvzQdSAIVaje7uy4laFW3KZwMHtSlLERJLp0mn01pIKCKSRZwEMhb434z3acKgdtlrakmTSussEBGR9nSYQNx9784IpBQ1NIfTCDUGIiKytQ4TiJkdR5huW0MYe9jB3T+cdGClQMfZiohkF6dv5qfAj4ElwC100uynUtDYFB1nq2m8IiJbifNkfMvd/wng7jcDwxONqIQ0NqsFIiKSTZwE0mhmE4EaMzsKGJRwTCWjQS0QEZGs4jwZzyGMlfwUOCv6WhFax0A0iC4isrU403h/ANxN2B7rswnHU1I2t0CUQEREthKnBfJ74AjgMTO7JZqVVRE2j4GoC0tEZCsdPhndfRbh7I1rCIsKr006qFKhFoiISHYdJhAze4FwDseOwJfcfUTiUZWILWMgaoGIiLQV58n4M+BFwp5VX4xmYlUErUQXEckuThfW7YRdci8D9gWmJx1UqdgyjVcJRESkrThdWPcCzxAG0r8PVEwX1paFhOrCEhFpK8403u8DbwC7AK3nlFeE1haIZmGJiGwtzpNxLPAI4YCnr5vZRYlGVEIam1qo7V5NVVVVsUMRESk5cRLIBYTDnVYTVqF/JtGISoiOsxURyS5OAmlx90YgHXVfbUg4ppLR2JxS95WISBZxno5PmNltwAgzux6Yk3BMJUMtEBGR7OKcSPg9M5sCPA/Mc/d7kw+rNDQ0pbSIUEQki6wJxMy6A8cBa9z9AeABMxtmZne4+0mdFmERNTSrBSIikk2uFsgfgWZgRzPbE3gdmAZc1RmBlYKGphYtIhQRySJXAhnt7vubWQ/gWaAR+IS7v9Y5oRVfY3OKPrVxlsqIiFSeXB38dQDuvimqd2QlJQ8IYyC1aoGIiLQr7gjx2+7+bqKRlKDGphYNoouIZJGrf2bPaPpuVcZrANz9lMQjKwGaxisikl2uBHJixuvrkw6kFGkhoYhIdlkTiLs/2pmBlCK1QEREstPH6xwamrWQUEQkGz0ds2hqSdGSSmsdiIhIFh0ucjCz4cDPgSHAn4EX3f2pQlzczAYCtwL9gHcIZ66vNLNjgR8SFjJOd/cbzKxXVHcIUA+c7u6rChFHe7ach64EIiLSnjgtkN8RjrGtAR6jsCvRvwc84e6HAL8GLjGzGuBK4Ejg48BZZjYUOAd4yd0PBX4PJHouSWNzdJiUurBERNoV5+nYy90fImzn7kBDAa//IeD+6PWTwCHAHsBCd18TLWJ8ApgYfe+BqO79wKQCxrGVzS0QdWGJiLQrzj4dDWZ2FNDNzA4izwRiZmcSDqfKtISwYePz0dfehO6sdRl16oH+bcpbyxKz+ThbtUBERNoVJ4GcBVwODAK+SehK+sDcfRphM8bNzKwvcLWZPQb8lZBQ6oC+GdX6AmvblLeWJUZjICIiucX5eF0NfBs4Gvg6oUVSU6DrTwRucPeJwEJCN9ZrwBgzGxht5DgR+Gf0vWOinzsaeLxAMbRr8xiIFhKKiLQrztNxBjAXuB14DngKeMPMvlCA6ztwuZnNAk4GfuruTYRENZOQOKa7+zLgOsKWKk8QWkUXF+D6WTWqBSIiklOcLqzXgcPdfbWZbQ/cCHyJMJB967Zc3N0XAge3U34vcG+bso3ACdtyvQ+ioVkJREQklzgtkKHuvhrA3ddE798FUolGVmStg+haiS4i0r44LZBnzexPhO6kjwJzzewk4O1EIysyTeMVEcmtw4/X7n4u8CegF3Cru3+FMCZS1lu6ayGhiEhucbYyGQhsB7wFDDKzC939Z4lHVmRqgYiI5BanC+sewtTavQmLCDcmGlGJ2DIGogQiItKeOP0zVe5+NmHK7WRgYLIhlYbWFojWgYiItC/O07HZzHoSurHSxGu1dHkNzS306FZNdXVVsUMRESlJcRLINcD5wIOErUZeTzSiEtHYlNIAuohIDnFaEz3d/VIAM/uzu9clHFNJaGzWcbYiIrnE+Yh9VuuLSkkeEAbRtYhQRCS7OC2QWjN7njCIngJw97JeAwJhEL1WU3hFRLKKk0C+k3gUJaixWS0QEZFc4jwhnyNM3z0d2AFYlmhEJaKhqUWLCEVEcoiTQKYDi4ExwAraHApVrhqaNIguIpJLnASyg7tPB5rcfVbMn+nyNIguIpJbrCekmY2Lvo4AmhONqEQ0NGsQXUQklziD6F8DbgL2AO4CvpxoRCVCCwlFRHKLk0BGAx9z97I+QKotLSQUEcktzkfsScALZvbfZrZr0gGVioamlGZhiYjkEOdAqa8C+xEOkbrGzP6eeFQloKGpRV1YIiI5xH1CHggcBQwFyj6BNLekaE6l1QIREcmhwwRiZq8C5wK3EZJI2Ws9zlbTeEVEsovzhDwUuBKYCrwEjEgyoFKw+ThbDaKLiGSVdRaWmfUAPkdofTQC/YDd3P29ToqtaBrUAhER6VCuJ+S/gA8Dn3f3Q4HllZA8IPM4W7VARESyybUO5FfA54FRZnYjUDFnuzY2qQUiItKRrE9Id7/M3ccDVwOnAAeY2c/NbK9Oi65IGpqjFojGQEREsoqzDuRRdz+VsCJ9KfCHxKMqss2D6OrCEhHJKs5WJgC4+1rg19G/stbahaWFhCIi2ekJ2Y7GZrVAREQ6ErsFUihm9hnghNZz1c3sIOAqwjbxD7r7xWZWDVwLjCdMIf4Pd1/YXt0kYpyw6w6cc9hoxg7tk8SvFxEpC53aAjGzq4Cftbnu9YRB+kOACWa2L/BpoKe7fxT4LnBFjroFt/12PfjOlHF076YGmohINp39hJwFnNP6xsz6AbXuvsjd08BMwu6/hwAPALj7bGD/HHVFRKQIEunCMrMzgQvaFJ/h7neY2WEZZf2Auoz39cBuUfm6jPKWHHVFRKQIEkkg7j4NmBajah3QN+N9X2At0LtNeXWOuiIiUgRF7eR39zpgk5mNNrMqwm6/jwNPAsfA5kH2l3LUFRGRIuj0WVjtOBv4I9CNMLPqKTObA0w2s1mELVTOyFa3GAGLiAhUpdPpYseQmOOPPz599913FzsMEZEuxcyedff9O6qneaoiIpIXJRAREclLKYyBJOaVV15ZbWZvFDsOEZEuZpc4lcp6DERERJKjLiwREcmLEoiIiORFCURERPKiBCIiInlRAhERkbyU9TTeuLIdYFXcqLadmdUA04FRQC3wU+BV4GYgDbwMnOvuKTP7EfBvhMO6znf3p81s9/bqdvJt5M3MhgDPApMJ93UzZX7fZnYhcBzQg/A3/Shlft/R3/kthL/zFuBLlPl/bzObAPzc3Q/LFv8Hudf26saJQy2QINsBVl3dF4B33P1QYArwG+CXwEVRWRXwKTP7CPBxYAIND111AAAFG0lEQVRwMnBN9PNb1e3k+PMWPVR+C7wXFZX9fUdHJRwMfIxwXyOpgPsmbLza3d0PBn4C/DdlfN9m9m3gRqBnVLRN95qjboeUQIKtDrAqbjgF82fgB9HrKsKni/0In0oB7mfLAV4Punva3d8EupvZ4Cx1u4rLCSdYLo/eV8J9HwW8BNwD3AvMoDLuez7hHqoJ5wY1Ud73vQg4PuP9tt5rtrodUgIJtjrAysy6fPeeu69393oz6wvcBVwEVEUnOkI4lKs/W99/a3l7dUuemU0FVrn7zIzisr9vYBDhw88JbNm5uroC7ns9oftqHnADcDVl/N/b3f+HkCRbbeu9ZqvbISWQoO1hVdXu3lysYArJzEYCDwN/cPfbgMy+3dZDubId1tVe3a7gi4TjAB4B9gF+DwzJ+H653vc7wEx33+TuDjTw/gdBud73BYT7HksYx7yFMAbUqlzvu9W2/n8678P6lECCrQ6wKm44hWFmQ4EHge+4+/So+PmMY4WPZssBXkeZWbWZ7UxIoKuz1C157j7R3T/u7ocBc4HTgPvL/b6BJ4ApZlZlZjsB2wH/qID7XsOWT9DvAjVUwN95hm2912x1O9Tlu2kK5B7aP8Cqq/sesD3wAzNrHQs5D7jazHoArwF3uXuLmT0O/JPwoeLcqO43gBsy63Zq9IW11b2U2327+wwzmwg8zZb7eZ0yv2/gSmB6dE89CH/3z1D+991qm/62c9TtkDZTFBGRvKgLS0RE8qIEIiIieVECERGRvCiBiIhIXpRAREQkL5rGK2Uvmvd+J2EjyVar3P2ELPX3AY5z959swzVXuPuwmLH9L7CXuy+Jyi4F5rn7zXleexRwu7sflM/Pi8SlBCKV4iF3PzlORXefS1iA2FkagZvMbHLGNhMiJU8JRCpatN3JPGAcYRHpSdHrs939ZDO7Cdgd6AVc5e5/MLPJhK3xGwjbh3yRsH/Q74A9CZvd1Ua/f2RU3ouwM/BZrS2NDA+xZQHXbzJiG0VGS8LMZhN2S50axTQI2IGwe+pngbHA6cAKYLCZ/R8wFJjh7v/VXixAN8LGi+8A97n7ZXn/jykVR2MgUikON7NHMv59K+N7s6JtT+4grGIGINqEciJh59MphE02qwgP4ePd/eOEnU0vAj5DOBLgIOBCoHf0ay4Hro5+/+XApVniOwe4IDqvIY733H0K8D/AMe5+bPS7W1tZfYBTCdu7H21m43PEMgw4UslDPii1QKRS5OrCeij6OouMsyCinYzPJySMfsCthE/9de6+LKr2GHAJYQ+mp6Ofe9PMWlsZewPfM7PvEFo4mbuobubu70TXuoWwN1F7qjJePxd9XcuWsZ01bDkj4gV3XwdgZk8TWifZYnnd3TdluaZIVmqBiIQzEiAcxPRKa6GZ7Qjs5+6fIZzWdhnhgd0v+h6Eg3jmEx7iH41+bidgePT9eYTNLA8D/pNwRku73P1ewAldVBC6yIaYWTczGwDsmlG9o7GSPcysT3QswYTovrLFUtKn70npUgtEKsXh0XhHpqOjr1PN7OvABkK3z95R+QpgWLTJZgtwubs3mdmXgLvNLEX41D+VMIYw2cyeAt4AWncz/SZwnZn1JIw9nNdBnOcDRwC4+woz+xswhzCu8kGOWX6X0CU3GLjD3V81sw8ai0hO2kxRKlqUVM5293nFjkWkq1EXloiI5EUtEBERyYtaICIikhclEBERyYsSiIiI5EUJRERE8qIEIiIieVECERGRvPw/zmz9s9Z7BZYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Average Reward over 100 Episodes: nan\n"
     ]
    }
   ],
   "source": [
    "policy, Q = sarsamax(env, 10000, alpha=0.02, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와씨 완벽하다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Sarsa\n",
    "\n",
    "Sarsamax가 next state의 value 중 최댓값을 골랐다면, expected sarsa는 policy를 활용해 기댓값을 구한다. 그때문에 expected라는 이름이 붙었다. 또 max값을 취하지 않기 때문에 policy를 그대로 사용하므로 on-policy method이다.\n",
    "\n",
    "구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def update_Q(Qsa, Qs_expected, reward, alpha, gamma):\n",
    "    # Q[s, a] = Q[s, a] + a * (r_1 + gamma * Qs_max - Qsa)\n",
    "    Qsa = Qsa + alpha * (reward + gamma * Qs_expected - Qsa)\n",
    "    return Qsa\n",
    "\n",
    "def expectedsarsa(env, num_episodes, alpha, gamma, eps_start=1.0, eps_min = 0.1, eps_decay_duration=3000):\n",
    "    \n",
    "    MAX_EPISODE_LENGTH = 300\n",
    "    PLOT_EVERY = 100\n",
    "    \n",
    "    tmp_scores = deque(maxlen=PLOT_EVERY)\n",
    "    scores = deque(maxlen=num_episodes)\n",
    "    \n",
    "    #init Q\n",
    "    Q = defaultdict(lambda: np.zeros(env.nA))\n",
    "    \n",
    "    epsilon_decay_angle = (eps_min - eps_start) / eps_decay_duration\n",
    "    epsilon = eps_start\n",
    "    \n",
    "    \n",
    "    # loop over ep\n",
    "    for i_episode in range(1, num_episodes+1):\n",
    "        \n",
    "        if i_episode % 100 == 0:\n",
    "            print(\"\\rEpisode {}/{}\".format(i_episode, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()   \n",
    "        \n",
    "        score = 0\n",
    "        \n",
    "        epsilon += epsilon_decay_angle\n",
    "        epsilon = max(eps_min, epsilon)\n",
    "        \n",
    "        # init state\n",
    "        state = env.reset()\n",
    "        \n",
    "        policy = get_probs(Q[state], epsilon, env.nA)\n",
    "        \n",
    "        for i in range(MAX_EPISODE_LENGTH):\n",
    "            \n",
    "            action = np.random.choice(np.arange(env.nA), p=policy)\n",
    "        \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                \n",
    "                Q[state][action] = update_Q(Q[state][action], 0, reward, alpha, gamma)\n",
    "                tmp_scores.append(score)\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # update Q\n",
    "                policy = get_probs(Q[next_state], epsilon, env.nA)\n",
    "                expected_Qs = np.dot(policy, Q[next_state])\n",
    "                Q[state][action] = update_Q(Q[state][action], expected_Qs, reward, alpha, gamma)\n",
    "                \n",
    "                state = next_state\n",
    "                \n",
    "        if i_episode % PLOT_EVERY == 0:\n",
    "            scores.append(np.mean(tmp_scores))\n",
    "            \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(np.linspace(0,num_episodes,len(scores),endpoint=False), np.array(scores))\n",
    "    ax.set_xlabel('Episode Number')\n",
    "    ax.set_ylabel('Average Reward (Over Next {:d} Episodes)'.format(PLOT_EVERY))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Best Average Reward over {:d} Episodes: {}\".format(PLOT_EVERY, np.max(scores)))\n",
    "    \n",
    "    policy = dict((k, np.argmax(v)) for k, v in Q.items())\n",
    "    return policy, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10000/10000"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Average Reward over 100 Episodes: -18.79\n"
     ]
    }
   ],
   "source": [
    "policy, Q = expectedsarsa(env, 10000, alpha=0.02, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expectedsarsa는 sarsa와 비슷한 결과를 보였다. 왜그랬을까?\n",
    "\n",
    "sarsamax에서 어떤 state의 값은 그 다음 state의 max value가 반영되었다. 즉, 바로 옆에 절벽이 있어 큰 페널티를 받을 확률이 있더라도 greedy 판정에 의해 해당 위험은 무시된다.\n",
    "\n",
    "하지만 expectedsarsa의 경우에는 그 확률도 감안한다. 위의 구현에서 epsilon은 0.1 이하로 떨어지지 않도록 고정되었다. 즉 아무리 작은 확률이라도 기댓값에 포함되기 때문에 이처럼 절벽으로부터 가급적 멀리 떨어져서 이동하려는 행태를 보이지 않나 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  x  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  x  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  x  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  x  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  x  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  x  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  x  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  x  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  x  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  x  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    env.render(mode='human')\n",
    "    sys.stdout.flush()\n",
    "    action = policy[state]\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        env.render(mode='human')\n",
    "        break \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete vs. Continuous\n",
    "\n",
    "지금까지 우리가 다룬 Cliff Walking 문제는 Discrete한 환경을 가지고 있다. env는 격자 형식의 grid world로 되어있다. agent의 이동은 셀 단위로 딱딱 나뉘어져 있다.\n",
    "\n",
    "반대로 우리가 하고 싶은 자율주행이나 달리기, 로봇제어는 행동의 단위가 continuous하다.\n",
    "\n",
    "그런데 지금까지 배운 알고리즘은 모두 discrete한 환경을 전제로 하니.. 어떡하지?\n",
    "\n",
    "여러가지 방법이 있다.\n",
    "\n",
    "하나는 continuous한 환경을 discrete하게 바꾸는 것이다. 이것이 바로 Discretization.\n",
    "\n",
    "<img src=\"assets/discretization.png\"></img>\n",
    "\n",
    "격자의 크기를 Cliff-Walking처럼 균일(uniform)하게 가져가지 않고 어디는 조밀하게 어디는 밀도가 낮게 구성하는 방식을 Non-Uniform Discretization이라 한다.\n",
    "\n",
    "Tile Coding이라는 방법도 있다. 다양한 크기의 격자를 가진 grid world를 여러개 생성한다. 그리고 해당 state를 처리할 때 각각의 grid world에 해당하는 영역을 대응시키는 방식이다.\n",
    "<img src=\"assets/tile_coding.png\"></img>\n",
    "\n",
    "\n",
    "또 다른 방법으로는 Coarse Coding도 있다. Tile Coding과 비슷한데, 이는 해당 state를 더 sparse한 vector로 표현하는 방법이다. 예컨대 공간안에 원을 여러개 뿌려놓고 state s에 해당하는 원의 index에 속하면 1, 아니면 0을 주는 방식으로 state를 표현한다.\n",
    "\n",
    "tile coding에서는 사각형 형태의 격자를 적용했지만 coarse coding에는 어떤 형태라도 상관없다. 만약 가우시안 분포를 따르는 형태로 coding을 하면, state의 위치가 특정 분포의 평균에 가깝다면 높은 값이 나오고 멀리간다면 낮은 값이 나온다. 즉, 1/0으로 처리되는 것이 아닌 continuous한 값으로 state를 정의할 수 있게 된다.\n",
    "\n",
    "## Function Approximation\n",
    "\n",
    "그런데 문제가 조금만 복잡해져도 필요한 discrete space가 엄청 커지기 때문에 이런 방식의 discretization은 적용하기 어려워진다. 또 근처에 위치한 state들은 값은 서로 비슷하거나 아니면 스무스하게 변하기 마련. discretization만으로는 이러한 특징을 잘 표현할 수 없다.\n",
    "\n",
    "우리가 도달하려고 하는 이상향 $v_{pi}(s)$, $q_{pi}(s, a)$는 고차원 평면상의 continuous한 space임. 간단한 문제 몇몇을 제외하고는 이런 고차원 space의 특징을 완벽히 잡아내기란 실질적으로 불가능함. 그래서 이를 approximate(근사)하자는 거다. $v_{pi}(s)$, $q_{pi}(s, a)$는 각각 state-value function, action-value function이므로 우리가 하려는 것은 function approximation.\n",
    "\n",
    "$\\hat{v}(s) \\approx v_{\\pi}(s)$  \n",
    "$\\hat{q}(s, a) \\approx q_{\\pi}(s, a)$\n",
    "\n",
    "근사를 하기 위해서는 어떤 변환작업을 거쳐야 하는데, 이때 사용할 parameter vector를 W라 하면 다음과 같이 표현할 수 있다.\n",
    "\n",
    "$\\hat{v}(s, W) \\approx v_{\\pi}(s)$  \n",
    "$\\hat{q}(s, a, W) \\approx q_{\\pi}(s, a)$\n",
    "\n",
    "그리고 우리가 해야 할일은 어느정도 만족스런 근사를 할때까지 W를 업데이트시켜나가는 것임.\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "가장 간단한 state-value function approximation을 살펴보자.\n",
    "state s를 W에 통과시키면 $\\hat{v}(s, W)$을 얻을 수 있다.\n",
    "$\\hat{v}(s, W)$에서 s는 state고, W는 parameter vector.\n",
    "이를 통해서 얻는 결과는 하나의 스칼라값(value)이다.\n",
    "\n",
    "이렇게 구하기 위해서 필요한 것은 state를 feature vector의 형식으로 표현해야 한다는 것. $X(s) = (x_1(s), x_2(s), ... , x_n(s))$\n",
    "\n",
    "만약 state가 애초에 vector로 표현되어있다면 굳이 변환할 필요는 없지만, Cliff Walking 문제처럼 격자의 id로 되어있는 경우에는 변환이 필요하겠다.\n",
    "\n",
    "feature vector화시키면서 다양한 변환을 적용할 수 있기 때문에 굳이 raw state만을 활용해야할 필요는 없다.\n",
    "\n",
    "얻으려는 최종 결과값이 scalar로, state를 변환한 X(s)가 vector, W도 vector라면 어떻게 하지? dot product!\n",
    "\n",
    "$\\hat{v}(s, W) = X(s)^T \\odot W$\n",
    "\n",
    "dot product는 linear combination과 같으므로\n",
    "\n",
    "$\\hat{v}(s, W) = \\Sigma_{j=1}^n x_j(s) w_j$\n",
    "\n",
    "이런 방식을 linear function appoximation이라고 한다.\n",
    "즉 underlying value function을 linear function을 사용해서 approximation하는 것임.\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "$\\hat{v}(s, W) = X(s)^T \\odot W$은 linear function이므로,\n",
    "$\\triangledown_W \\hat{v}(s, W) = X(s)$\n",
    "w에 대한 $\\hat{v}$의 derivative는 X(s)가 된다.\n",
    "\n",
    "학습의 목표는 $\\hat{v}$와 true value인 $v_{\\pi}$와의 Error를 최소화하는 것.\n",
    "\n",
    "즉, $J(w) = E_{\\pi}[(v_{\\pi}(s) - X(s)^T W)^2]$ \n",
    "RL의 도메인은 stochastic하므로 기댓값을 씌워준다.\n",
    "\n",
    "이제 error의 w에 대한 gradient를 구한다.\n",
    "\n",
    "$\\triangledown_W J(W) = -2(v_{\\pi}(s) - X(s)^TW)x(s)$\n",
    "여기서는 E를 빼버렸다. 하나의 state s가 가리키는 error gradient에 집중하기 위해서.  s는 stochastic하게 결정된다. 샘플을 무한히 뽑다보면 결국 이 값도 평균에 수렴하게 된다.\n",
    "\n",
    "이를 다음과 같은 식으로 업데이트한다.\n",
    "\n",
    "$\\triangle W = - \\alpha {1\\over2} \\triangledown_{W} J(W)$  \n",
    "$\\triangle W = \\alpha (v_{\\pi}(s) - X(s)^T W)X(s)$\n",
    "\n",
    "$\\alpha$는 이미 아는 것처럼 step size, learning_rate parameter다.  \n",
    "$-{1\\over2}$는 derivative를 구할때 얻은 -2를 상쇄하는 상수다.\n",
    "true function과 approximation function이 거의 같아질때까지 이 업데이트를 반복한다.\n",
    "\n",
    "At every update, change weights ($\\triangle W$) by step step $\\alpha$ away from error ($(v_{\\pi}(s) - X(s)^T W)$ in the direction of $X(s)$\n",
    "\n",
    "\n",
    "### action-value function approximation\n",
    "\n",
    "action-value function은 state s와 action a를 input으로 한다.\n",
    "\n",
    "$\\hat{q}(s, a, W) \\approx q_{\\pi}(s, a)$\n",
    "\n",
    "state-value function에 action 인자가 하나 더 들어갈 뿐, $W$ parameter vector를 쓰는 것은 변하지 않는다.\n",
    "\n",
    "다만 state s는 여러개의 a를 가지기 때문에 a의 갯수만큼 action-value function을 approximation하는 것은 비효율적으로 보인다.\n",
    "\n",
    "또 자율주행을 한다고 했을때 핸들의 방향을 트는 action과 액셀을 밟은 action은 동시에 이루어지므로 개별 action-value function을 하나하나 계산하는 것보다, 모든 action에 대해 한번에 계산하는 것이 더 낫다.\n",
    "\n",
    "즉, s에서의 action이 4가지라고 하면 s를 넣어 $\\hat{q}(s, a_1, W)$부터 $\\hat{q}(s, a_4, W)$까지의 value를 approximation한다.\n",
    "\n",
    "이때 늘어난 action의 갯수에 대해서 가중치 계산을 해야 하므로,\n",
    "곱해주는 W 파라미터 벡터를 벡터가 아닌 매트릭스로 정의한다.\n",
    "\n",
    "action은 이때 vector가 되므로 이를 action-vector appoximation이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Function Approximation\n",
    "\n",
    "앞서 Linear Function을 사용해서 $\\hat{q}(s, a, W)$을 정의하고, gradient descent 방식을 사용해서 업데이트하는 방식을 알아보았다.\n",
    "\n",
    "그런데 Linear Function은 아무리 층을 깊게 쌓아도 결국 Linear Function으로 재정의할 수 있다. 그렇다는 것은 층의 깊이와 관계없이 표현할 수 있는 형태가 매우 제한적임을 의미한다.\n",
    "\n",
    "고차원 space에 있는 복잡한 true value function을 approximation하기 위해서는 근사하는 function 역시 표현력이 좋아야 하며, 이를 위해 non-linear activation function $f$를 씌운다.\n",
    "\n",
    "$\\hat{v}(s, W) = f(X(s)^T \\cdot W)$\n",
    "\n",
    "음? 어디서 많이 본 수식이 나온다.\n",
    "이게 바로 인공신경망의 기본적인 형태다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
